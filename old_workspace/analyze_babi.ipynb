{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3177cbd1-3cce-46f5-b243-10eeeebe716e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world\n",
      "tensor([[0.3185, 0.7728, 0.4545],\n",
      "        [0.6348, 0.0011, 0.6349],\n",
      "        [0.9181, 0.7950, 0.6944],\n",
      "        [0.7936, 0.5319, 0.1988],\n",
      "        [0.0226, 0.9504, 0.3940]])\n",
      "True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0.3185, 0.6348, 0.9181, 0.7936, 0.0226])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"hello world\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ed2b2c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float(\"0.16\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4adc2eba-52ad-4874-9d10-7e7179b21566",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torchtext\n",
    "from torchtext.datasets import BABI20\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "bf49136e-478e-4c27-a18b-26043ab49d52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torchtext/data/field.py:150: UserWarning: BABI20Field class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n",
      "/usr/local/lib/python3.8/dist-packages/torchtext/data/example.py:78: UserWarning: Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.', UserWarning)\n",
      "/usr/local/lib/python3.8/dist-packages/torchtext/data/iterator.py:48: UserWarning: Iterator class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "#a,b,c = torchtext.datasets.BABI20.iters(torch.device('cuda'))\n",
    "a,b,c = torchtext.datasets.BABI20.iters()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0b94783c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torchtext/data/batch.py:23: UserWarning: Batch class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "[torchtext.data.batch.Batch of size 32 from ]\n",
       "\t[.story]:[torch.LongTensor of size 32x50x6]\n",
       "\t[.query]:[torch.LongTensor of size 32x3]\n",
       "\t[.answer]:[torch.LongTensor of size 32x1]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d0263913",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torchtext/data/batch.py:23: UserWarning: Batch class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "for i,batch in enumerate(b):\n",
    "    FFFFFFF=0\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7ded9c5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torchtext.data.batch.Batch'>\n",
      "['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_get_field_values', 'answer', 'batch_size', 'dataset', 'fields', 'fromvars', 'input_fields', 'query', 'story', 'target_fields']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torchtext/data/batch.py:23: UserWarning: Batch class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "for i,batch in enumerate(b):\n",
    "    kkt=0\n",
    "print(type(batch))\n",
    "print(dir(batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "ce2e40bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__add__', '__class__', '__class_getitem__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattr__', '__getattribute__', '__getitem__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__module__', '__ne__', '__new__', '__orig_bases__', '__parameters__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__slots__', '__str__', '__subclasshook__', '__weakref__', '_is_protocol', '_parse', 'dirname', 'download', 'filter_examples', 'iters', 'name', 'sort_key', 'split', 'splits', 'urls']\n",
      "['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_iterations_this_epoch', '_random_state_this_epoch', '_restored_from_state', 'batch_size', 'batch_size_fn', 'batches', 'create_batches', 'data', 'dataset', 'device', 'epoch', 'init_epoch', 'iterations', 'load_state_dict', 'random_shuffler', 'repeat', 'shuffle', 'sort', 'sort_key', 'sort_within_batch', 'splits', 'state_dict', 'train']\n"
     ]
    }
   ],
   "source": [
    "print(dir(BABI20))\n",
    "print(dir(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "168b3bf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class BABI20 in module torchtext.datasets.babi:\n",
      "\n",
      "class BABI20(torchtext.data.dataset.Dataset)\n",
      " |  BABI20(*args, **kwds)\n",
      " |  \n",
      " |  Defines a dataset composed of Examples along with its Fields.\n",
      " |  \n",
      " |  Attributes:\n",
      " |      sort_key (callable): A key to use for sorting dataset examples for batching\n",
      " |          together examples with similar lengths to minimize padding.\n",
      " |      examples (list(Example)): The examples in this dataset.\n",
      " |      fields (dict[str, Field]): Contains the name of each column or field, together\n",
      " |          with the corresponding Field object. Two fields with the same Field object\n",
      " |          will have a shared vocabulary.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      BABI20\n",
      " |      torchtext.data.dataset.Dataset\n",
      " |      torch.utils.data.dataset.Dataset\n",
      " |      typing.Generic\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, path, text_field, only_supporting=False, **kwargs)\n",
      " |      Create a dataset from a list of Examples and Fields.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          examples: List of Examples.\n",
      " |          fields (List(tuple(str, Field))): The Fields to use in this tuple. The\n",
      " |              string is a field name, and the Field is the associated field.\n",
      " |          filter_pred (callable or None): Use only examples for which\n",
      " |              filter_pred(example) is True, or use all examples if None.\n",
      " |              Default is None.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods defined here:\n",
      " |  \n",
      " |  iters(batch_size=32, root='.data', memory_size=50, task=1, joint=False, tenK=False, only_supporting=False, sort=False, shuffle=False, device=None, **kwargs) from builtins.type\n",
      " |  \n",
      " |  splits(text_field, path=None, root='.data', task=1, joint=False, tenK=False, only_supporting=False, train=None, validation=None, test=None, **kwargs) from builtins.type\n",
      " |      Create Dataset objects for multiple splits of a dataset.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          path (str): Common prefix of the splits' file paths, or None to use\n",
      " |              the result of cls.download(root).\n",
      " |          root (str): Root dataset storage directory. Default is '.data'.\n",
      " |          train (str): Suffix to add to path for the train set, or None for no\n",
      " |              train set. Default is None.\n",
      " |          validation (str): Suffix to add to path for the validation set, or None\n",
      " |              for no validation set. Default is None.\n",
      " |          test (str): Suffix to add to path for the test set, or None for no test\n",
      " |              set. Default is None.\n",
      " |          Remaining keyword arguments: Passed to the constructor of the\n",
      " |              Dataset (sub)class being used.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Tuple[Dataset]: Datasets for train, validation, and\n",
      " |          test splits in that order, if provided.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __parameters__ = ()\n",
      " |  \n",
      " |  dirname = 'tasks_1-20_v1-2/en-valid'\n",
      " |  \n",
      " |  name = ''\n",
      " |  \n",
      " |  urls = ['http://www.thespermwhale.com/jaseweston/babi/tasks_1-20_v1-2....\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from torchtext.data.dataset.Dataset:\n",
      " |  \n",
      " |  __getattr__(self, attr)\n",
      " |  \n",
      " |  __getitem__(self, i)\n",
      " |  \n",
      " |  __iter__(self)\n",
      " |  \n",
      " |  __len__(self)\n",
      " |  \n",
      " |  filter_examples(self, field_names)\n",
      " |      Remove unknown words from dataset examples with respect to given field.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          field_names (list(str)): Within example only the parts with field names in\n",
      " |              field_names will have their unknown words deleted.\n",
      " |  \n",
      " |  split(self, split_ratio=0.7, stratified=False, strata_field='label', random_state=None)\n",
      " |      Create train-test(-valid?) splits from the instance's examples.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          split_ratio (float or List of floats): a number [0, 1] denoting the amount\n",
      " |              of data to be used for the training split (rest is used for test),\n",
      " |              or a list of numbers denoting the relative sizes of train, test and valid\n",
      " |              splits respectively. If the relative size for valid is missing, only the\n",
      " |              train-test split is returned. Default is 0.7 (for the train set).\n",
      " |          stratified (bool): whether the sampling should be stratified.\n",
      " |              Default is False.\n",
      " |          strata_field (str): name of the examples Field stratified over.\n",
      " |              Default is 'label' for the conventional label field.\n",
      " |          random_state (tuple): the random seed used for shuffling.\n",
      " |              A return value of `random.getstate()`.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Tuple[Dataset]: Datasets for train, validation, and\n",
      " |          test splits in that order, if the splits are provided.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from torchtext.data.dataset.Dataset:\n",
      " |  \n",
      " |  download(root, check=None) from builtins.type\n",
      " |      Download and unzip an online archive (.zip, .gz, or .tgz).\n",
      " |      \n",
      " |      Arguments:\n",
      " |          root (str): Folder to download data to.\n",
      " |          check (str or None): Folder whose existence indicates\n",
      " |              that the dataset has already been downloaded, or\n",
      " |              None to check the existence of root/{cls.name}.\n",
      " |      \n",
      " |      Returns:\n",
      " |          str: Path to extracted dataset.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from torchtext.data.dataset.Dataset:\n",
      " |  \n",
      " |  sort_key = None\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from torch.utils.data.dataset.Dataset:\n",
      " |  \n",
      " |  __add__(self, other: 'Dataset[T_co]') -> 'ConcatDataset[T_co]'\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from torch.utils.data.dataset.Dataset:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from torch.utils.data.dataset.Dataset:\n",
      " |  \n",
      " |  __orig_bases__ = (typing.Generic[+T_co],)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from typing.Generic:\n",
      " |  \n",
      " |  __class_getitem__(params) from builtins.type\n",
      " |  \n",
      " |  __init_subclass__(*args, **kwargs) from builtins.type\n",
      " |      This method is called when a class is subclassed.\n",
      " |      \n",
      " |      The default implementation does nothing. It may be\n",
      " |      overridden to extend subclasses.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods inherited from typing.Generic:\n",
      " |  \n",
      " |  __new__(cls, *args, **kwds)\n",
      " |      Create and return a new object.  See help(type) for accurate signature.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(BABI20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "d48aac93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on generator object:\n",
      "\n",
      "__getattr__ = class generator(object)\n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __del__(...)\n",
      " |  \n",
      " |  __getattribute__(self, name, /)\n",
      " |      Return getattr(self, name).\n",
      " |  \n",
      " |  __iter__(self, /)\n",
      " |      Implement iter(self).\n",
      " |  \n",
      " |  __next__(self, /)\n",
      " |      Implement next(self).\n",
      " |  \n",
      " |  __repr__(self, /)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  close(...)\n",
      " |      close() -> raise GeneratorExit inside generator.\n",
      " |  \n",
      " |  send(...)\n",
      " |      send(arg) -> send 'arg' into generator,\n",
      " |      return next yielded value or raise StopIteration.\n",
      " |  \n",
      " |  throw(...)\n",
      " |      throw(typ[,val[,tb]]) -> raise exception in generator,\n",
      " |      return next yielded value or raise StopIteration.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  gi_code\n",
      " |  \n",
      " |  gi_frame\n",
      " |  \n",
      " |  gi_running\n",
      " |  \n",
      " |  gi_yieldfrom\n",
      " |      object being iterated by yield from, or None\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(a.dataset.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b6de38fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__init__\n",
      "__iter__\n",
      "__len__\n",
      "__repr__\n",
      "__str__\n",
      "_get_field_values\n",
      "fromvars\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torchtext/data/batch.py:23: UserWarning: Batch class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import inspect\n",
    "for i,batch in enumerate(a):\n",
    "    kkt=0\n",
    "for x in inspect.getmembers(batch, inspect.ismethod):\n",
    "  print(x[0])\n",
    "len(batch) # = batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "617475a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_size:   4\n",
      "fields:   dict_keys(['story', 'query', 'answer'])\n",
      "input_fields:   ['story', 'query', 'answer']\n",
      "target_fields:   []\n",
      "fromvars:   <bound method Batch.fromvars of <class 'torchtext.data.batch.Batch'>>\n"
     ]
    }
   ],
   "source": [
    "for i,batch in enumerate(b):\n",
    "    kkt=0\n",
    "print(\"batch_size:  \",batch.batch_size)\n",
    "print(\"fields:  \",batch.fields)\n",
    "print(\"input_fields:  \",batch.input_fields)\n",
    "print(\"target_fields:  \",batch.target_fields)\n",
    "print(\"fromvars:  \",batch.fromvars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "3e833ed2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query_size:   torch.Size([4, 3])\n",
      "answer_size:   torch.Size([4, 1])\n",
      "story_size:   torch.Size([4, 50, 6])\n",
      "query:   tensor([[18, 19,  6],\n",
      "        [18, 19,  7],\n",
      "        [18, 19,  4],\n",
      "        [18, 19,  5]])\n",
      "answer:   tensor([[16],\n",
      "        [14],\n",
      "        [17],\n",
      "        [16]])\n",
      "story:   tensor([[[ 5, 11,  2,  1,  8,  0],\n",
      "         [ 4,  3, 13,  2,  1, 14],\n",
      "         [ 6,  9,  2,  1, 16,  0],\n",
      "         [ 4,  3,  2,  1, 16,  0],\n",
      "         [ 0,  0,  0,  0,  0,  0]],\n",
      "\n",
      "        [[ 7,  9,  2,  1, 14,  0],\n",
      "         [ 4,  3, 13,  2,  1, 17],\n",
      "         [ 5, 11,  2,  1,  8,  0],\n",
      "         [ 4,  3, 13,  2,  1, 14],\n",
      "         [ 6,  9,  2,  1, 16,  0]],\n",
      "\n",
      "        [[ 5, 10,  2,  1, 17,  0],\n",
      "         [ 6, 10,  2,  1,  8,  0],\n",
      "         [ 7,  9,  2,  1, 14,  0],\n",
      "         [ 4,  3, 13,  2,  1, 17],\n",
      "         [ 5, 11,  2,  1,  8,  0]],\n",
      "\n",
      "        [[ 5,  3,  2,  1, 16,  0],\n",
      "         [ 6,  3, 13,  2,  1, 15],\n",
      "         [ 5, 10,  2,  1, 17,  0],\n",
      "         [ 6, 10,  2,  1,  8,  0],\n",
      "         [ 7,  9,  2,  1, 14,  0]]])\n"
     ]
    }
   ],
   "source": [
    "print(\"query_size:  \",batch.query.size())\n",
    "print(\"answer_size:  \",batch.answer.size())\n",
    "print(\"story_size:  \",batch.story.size())\n",
    "print(\"query:  \",batch.query)\n",
    "print(\"answer:  \",batch.answer)\n",
    "print(\"story:  \",batch.story[:,:5,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "57d79b3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torchtext.datasets.babi.BABI20"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(batch.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "c66ad8a9",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Iterator' object has no attribute 'vocab'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [112], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43ma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvocab\u001b[49m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Iterator' object has no attribute 'vocab'"
     ]
    }
   ],
   "source": [
    "print(a.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "de0d73c7-f52a-4dcb-95a7-e2acf1288953",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'type'>\n",
      "__class_getitem__\n",
      "__init_subclass__\n",
      "download\n",
      "iters\n",
      "splits\n"
     ]
    }
   ],
   "source": [
    "import inspect\n",
    "obj=torchtext.datasets.BABI20\n",
    "print(type(obj))\n",
    "for x in inspect.getmembers(obj, inspect.ismethod):\n",
    "  print(x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b04f49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from io import open\n",
    "\n",
    "import torch\n",
    "\n",
    "from ..data import Dataset, Field, Example, Iterator\n",
    "\n",
    "\n",
    "class BABI20Field(Field):\n",
    "\n",
    "    def __init__(self, memory_size, **kwargs):\n",
    "        super(BABI20Field, self).__init__(**kwargs)\n",
    "        self.memory_size = memory_size\n",
    "        self.unk_token = None\n",
    "        self.batch_first = True\n",
    "\n",
    "    def preprocess(self, x):\n",
    "        if isinstance(x, list):\n",
    "            return [super(BABI20Field, self).preprocess(s) for s in x]\n",
    "        else:\n",
    "            return super(BABI20Field, self).preprocess(x)\n",
    "\n",
    "    def pad(self, minibatch):\n",
    "        if isinstance(minibatch[0][0], list):\n",
    "            self.fix_length = max(max(len(x) for x in ex) for ex in minibatch)\n",
    "            padded = []\n",
    "            for ex in minibatch:\n",
    "                # sentences are indexed in reverse order and truncated to memory_size\n",
    "                nex = ex[::-1][:self.memory_size]\n",
    "                padded.append(\n",
    "                    super(BABI20Field, self).pad(nex)\n",
    "                    + [[self.pad_token] * self.fix_length]\n",
    "                    * (self.memory_size - len(nex)))\n",
    "            self.fix_length = None\n",
    "            return padded\n",
    "        else:\n",
    "            return super(BABI20Field, self).pad(minibatch)\n",
    "\n",
    "    def numericalize(self, arr, device=None):\n",
    "        if isinstance(arr[0][0], list):\n",
    "            tmp = [\n",
    "                super(BABI20Field, self).numericalize(x, device=device).data\n",
    "                for x in arr\n",
    "            ]\n",
    "            arr = torch.stack(tmp)\n",
    "            if self.sequential:\n",
    "                arr = arr.contiguous()\n",
    "            return arr\n",
    "        else:\n",
    "            return super(BABI20Field, self).numericalize(arr, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd6ea44",
   "metadata": {},
   "source": [
    "以下はBABI20クラスのiters()メソッドの中身からtextのFieldを取り出しbuild_vocabした情報を取り出そうとした残骸  \n",
    "公式コードの再現さえできれば、field.vocab.itosで望む変換はできそうなので、こっちの問題は解決とみていい  \n",
    "今はpytorchでbabiを処理してる既存コードを探すほうが先"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "73cf8d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from io import open\n",
    "\n",
    "import torch\n",
    "\n",
    "from torchtext.data import Dataset, Field, Example, Iterator\n",
    "\n",
    "\n",
    "class BABI20Field(Field):\n",
    "\n",
    "    def __init__(self, memory_size, **kwargs):\n",
    "        super(BABI20Field, self).__init__(**kwargs)\n",
    "        self.memory_size = memory_size\n",
    "        self.unk_token = None\n",
    "        self.batch_first = True\n",
    "\n",
    "    def preprocess(self, x):\n",
    "        if isinstance(x, list):\n",
    "            return [super(BABI20Field, self).preprocess(s) for s in x]\n",
    "        else:\n",
    "            return super(BABI20Field, self).preprocess(x)\n",
    "\n",
    "    def pad(self, minibatch):\n",
    "        if isinstance(minibatch[0][0], list):\n",
    "            self.fix_length = max(max(len(x) for x in ex) for ex in minibatch)\n",
    "            padded = []\n",
    "            for ex in minibatch:\n",
    "                # sentences are indexed in reverse order and truncated to memory_size\n",
    "                nex = ex[::-1][:self.memory_size]\n",
    "                padded.append(\n",
    "                    super(BABI20Field, self).pad(nex)\n",
    "                    + [[self.pad_token] * self.fix_length]\n",
    "                    * (self.memory_size - len(nex)))\n",
    "            self.fix_length = None\n",
    "            return padded\n",
    "        else:\n",
    "            return super(BABI20Field, self).pad(minibatch)\n",
    "\n",
    "    def numericalize(self, arr, device=None):\n",
    "        if isinstance(arr[0][0], list):\n",
    "            tmp = [\n",
    "                super(BABI20Field, self).numericalize(x, device=device).data\n",
    "                for x in arr\n",
    "            ]\n",
    "            arr = torch.stack(tmp)\n",
    "            if self.sequential:\n",
    "                arr = arr.contiguous()\n",
    "            return arr\n",
    "        else:\n",
    "            return super(BABI20Field, self).numericalize(arr, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "880b43ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['UNK',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_default_unk_index',\n",
       " 'extend',\n",
       " 'freqs',\n",
       " 'itos',\n",
       " 'load_vectors',\n",
       " 'lookup_indices',\n",
       " 'set_vectors',\n",
       " 'stoi',\n",
       " 'unk_index',\n",
       " 'vectors']"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "field =BABI20Field(50)\n",
    "field.build_vocab([\"hello\",\"world\"])\n",
    "dir(field.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "cfd3366e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'l': 3, 'o': 2, 'h': 1, 'e': 1, 'w': 1, 'r': 1, 'd': 1})\n",
      "defaultdict(None, {'<pad>': 0, 'l': 1, 'o': 2, 'd': 3, 'e': 4, 'h': 5, 'r': 6, 'w': 7})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "collections.defaultdict"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(field.vocab.freqs)\n",
    "print(field.vocab.stoi)\n",
    "type(field.vocab.stoi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "8589a071",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'root' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [110], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m text \u001b[38;5;241m=\u001b[39m BABI20Field(\u001b[38;5;241m50\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m train, val, test \u001b[38;5;241m=\u001b[39m BABI20\u001b[38;5;241m.\u001b[39msplits(text, root\u001b[38;5;241m=\u001b[39m\u001b[43mroot\u001b[49m, task\u001b[38;5;241m=\u001b[39mtask, joint\u001b[38;5;241m=\u001b[39mjoint,\n\u001b[1;32m      3\u001b[0m                                          tenK\u001b[38;5;241m=\u001b[39mtenK, only_supporting\u001b[38;5;241m=\u001b[39monly_supporting,\n\u001b[1;32m      4\u001b[0m                                          \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m      5\u001b[0m text\u001b[38;5;241m.\u001b[39mbuild_vocab(train)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'root' is not defined"
     ]
    }
   ],
   "source": [
    "text = BABI20Field(50)\n",
    "train, val, test = BABI20.splits(text, root=root, task=task, joint=joint,\n",
    "                                         tenK=tenK, only_supporting=only_supporting,\n",
    "                                         **kwargs)\n",
    "text.build_vocab(train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
