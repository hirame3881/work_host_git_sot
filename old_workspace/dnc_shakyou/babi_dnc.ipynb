{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6f309ee-a304-41aa-89ca-3632143dc171",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "import getopt\n",
    "import sys\n",
    "import os\n",
    "import math\n",
    "import time\n",
    "import argparse\n",
    "import torch\n",
    "import torch as T\n",
    "from torch.autograd import Variable as var\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "\n",
    "#torch.manual_seed(1)\n",
    "\n",
    "\n",
    "import os\n",
    "from io import open\n",
    "import inspect\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torchtext\n",
    "from torchtext.datasets import BABI20\n",
    "from torchtext.data import Dataset, Field, Example, Iterator\n",
    "\n",
    "import argparse\n",
    "from torchtext import datasets\n",
    "from torchtext.datasets.babi import BABI20Field\n",
    "#from models.UTransformer import BabiUTransformer\n",
    "#from models.common_layer import NoamOpt\n",
    "import torch.nn as nn\n",
    "from copy import deepcopy\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import getopt\n",
    "import sys\n",
    "import os\n",
    "import math\n",
    "import time\n",
    "import argparse\n",
    "from visdom import Visdom\n",
    "\n",
    "sys.path.insert(0, os.path.join('..', '..'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8f969bb-dd2e-49ce-9eb3-4257cae8cc8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import torch as T\n",
    "from torch.autograd import Variable as var\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.nn.utils import clip_grad_norm_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5df9bd80-0dba-4e2e-9de2-713d8193dbb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with __import__('importnb').Notebook(): \n",
    "    from dnc import DNC\n",
    "    from util import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e44bf347",
   "metadata": {},
   "outputs": [],
   "source": [
    "def arrangestory(batch_story): # (batch,length,size)\n",
    "    strysum =torch.sum(batch_story,(0,2)) #1D\n",
    "    fill_length=len(strysum[torch.where(strysum!=0)])\n",
    "    red_story=batch_story[:,:fill_length,:]\n",
    "    red_story =torch.flip(red_story, dims=[1])\n",
    "    flat_story =red_story.view(len(batch_story),-1)\n",
    "    return flat_story #(batch, red_length * size ) 2D\n",
    "\n",
    "def prep_data(batch,vocab_size):\n",
    "    batch_size=batch.story.size()[0]\n",
    "    flat_story =arrangestory(batch.story)\n",
    "    story_OH =torch.nn.functional.one_hot(flat_story,num_classes=vocab_size) #(batch, seq_len, vocab_len)\n",
    "    query_OH=torch.nn.functional.one_hot(batch.query,num_classes=vocab_size) #(batch, que_len=3, vocab_len)\n",
    "    answer_OH=torch.nn.functional.one_hot(batch.answer,num_classes=vocab_size) #(batch,1, vocab_len)\n",
    "    querystop =torch.nn.functional.one_hot(torch.tensor([vocab_size-1]*batch_size),num_classes=vocab_size)\n",
    "    querystop=querystop.view(batch_size,1,-1) #2D -> 3D\n",
    "    x =torch.cat((story_OH,query_OH,querystop),1)\n",
    "    y =answer_OH.view(batch_size,vocab_size)\n",
    "    ans_id =batch.answer.view(-1) #1D (batch_size)\n",
    "\n",
    "\n",
    "\n",
    "    #x = var(x.detach().clone().to(torch.float).cuda() )\n",
    "    #y = var(y.detach().clone().to(torch.float).cuda() )\n",
    "    x = var(x.detach().clone().to(torch.float).cuda() )\n",
    "    y = var(y.detach().clone().to(torch.float).cuda() )\n",
    "    ans_id=var(ans_id.cuda() )\n",
    "    #ans_id=var(ans_id.detach().clone().cuda() )\n",
    "\n",
    "    return x,y,ans_id #yはonehotなので2Dだけどans_idは1D !!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2151d042-e7ed-4232-9933-feb28efb7250",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreTrueAction(option_strings=['-visdom'], dest='visdom', nargs=0, const=True, default=False, type=None, choices=None, help='plot memory content on visdom per -summarize_freq steps', metavar=None)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser(description='PyTorch Differentiable Neural Computer')\n",
    "parser.add_argument('-input_size', type=int, default=6, help='dimension of input feature')\n",
    "parser.add_argument('-rnn_type', type=str, default='lstm', help='type of recurrent cells to use for the controller')\n",
    "parser.add_argument('-nhid', type=int, default=64, help='number of hidden units of the inner nn')\n",
    "parser.add_argument('-dropout', type=float, default=0, help='controller dropout')\n",
    "parser.add_argument('-memory_type', type=str, default='dnc', help='dense or sparse memory: dnc | sdnc | sam')\n",
    "\n",
    "parser.add_argument('-nlayer', type=int, default=1, help='number of layers')\n",
    "parser.add_argument('-nhlayer', type=int, default=2, help='number of hidden layers')\n",
    "parser.add_argument('-lr', type=float, default=1e-4, help='initial learning rate')\n",
    "parser.add_argument('-optim', type=str, default='adam', help='learning rule, supports adam|rmsprop')\n",
    "parser.add_argument('-clip', type=float, default=50, help='gradient clipping')\n",
    "\n",
    "parser.add_argument('-batch_size', type=int, default=100, metavar='N', help='batch size')\n",
    "parser.add_argument('-mem_size', type=int, default=20, help='memory dimension')\n",
    "parser.add_argument('-mem_slot', type=int, default=16, help='number of memory slots')\n",
    "parser.add_argument('-read_heads', type=int, default=4, help='number of read heads')\n",
    "parser.add_argument('-sparse_reads', type=int, default=10, help='number of sparse reads per read head')\n",
    "parser.add_argument('-temporal_reads', type=int, default=2, help='number of temporal reads')\n",
    "\n",
    "parser.add_argument('-sequence_max_length', type=int, default=4, metavar='N', help='sequence_max_length')\n",
    "parser.add_argument('-curriculum_increment', type=int, default=0, metavar='N', help='sequence_max_length incrementor per 1K iterations')\n",
    "parser.add_argument('-curriculum_freq', type=int, default=1000, metavar='N', help='sequence_max_length incrementor per 1K iterations')\n",
    "parser.add_argument('-cuda', type=int, default=-1, help='Cuda GPU ID, -1 for CPU')\n",
    "\n",
    "parser.add_argument('-iterations', type=int, default=100000, metavar='N', help='total number of iteration')\n",
    "parser.add_argument('-summarize_freq', type=int, default=100, metavar='N', help='summarize frequency')\n",
    "parser.add_argument('-check_freq', type=int, default=100, metavar='N', help='check point frequency')\n",
    "parser.add_argument('-visdom', action='store_true', help='plot memory content on visdom per -summarize_freq steps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e4355e24-db10-4759-a810-f5a0ab39f51e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA.\n"
     ]
    }
   ],
   "source": [
    "args = parser.parse_args(args=\"-rnn_type lstm -nhid 256 -lr 1e-3 -optim rmsprop -batch_size 50 -mem_size 64 -mem_slot 256 -sequence_max_length 50 -cuda 0 -iterations 1000 -summarize_freq 10 -check_freq 11000\".split(\" \"))\n",
    "\n",
    "#viz = Visdom()\n",
    "# assert viz.check_connection()\n",
    "\n",
    "if args.cuda != -1:\n",
    "  print('Using CUDA.')\n",
    "  #T.manual_seed(1111)\n",
    "else:\n",
    "  print('Using CPU.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a1da84b-d96a-4b6b-bb06-833d619407eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llprint(message):\n",
    "  sys.stdout.write(message)\n",
    "  sys.stdout.flush()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad2a88fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_criterion(predictions, targets):\n",
    "  return T.mean(\n",
    "      -1 * F.logsigmoid(predictions) * (targets) - T.log(1 - F.sigmoid(predictions) + 1e-9) * (1 - targets)\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b8a770df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_babidata_task_etc(task,batch_size, length, size): #~size\n",
    "    \"\"\"(batch_size=config.batch_size, \n",
    "                                                            root='.data', \n",
    "                                                            memory_size=70, \n",
    "                                                            task=config.task, \n",
    "                                                            joint=False,\n",
    "                                                            tenK=False, \n",
    "                                                            only_supporting=False, \n",
    "                                                            sort=False, \n",
    "                                                            shuffle=True)\"\"\"\n",
    "    text = BABI20Field(length)\n",
    "    train, val, test = datasets.BABI20.splits(text, root='.data', task=task, joint=False,\n",
    "                                            tenK=True, only_supporting=False)\n",
    "    text.build_vocab(train)\n",
    "    #text.vocab.append_token\n",
    "    vocab_len = len(text.vocab.freqs) +1\n",
    "    vocab_lenplus =vocab_len+1 # \"?\"\n",
    "    print(\"VOCAB LEN PLUS:\",vocab_lenplus )\n",
    "    train_iter,val_iter,test_iter = Iterator.splits((train, val, test),batch_size=batch_size)\n",
    "    return train_iter, val_iter, test_iter,vocab_lenplus,text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "70a7a709-6991-4d2a-b409-6082e8628b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_dnc_babi(task):\n",
    "  print(\"==========task:\",task)\n",
    "  dirname = os.path.dirname(os.path.abspath('__file__'))\n",
    "  ckpts_dir = 'checkpoints'\n",
    "  if not os.path.isdir(ckpts_dir):\n",
    "    os.mkdir(ckpts_dir)\n",
    "\n",
    "  \n",
    "  sequence_max_length = args.sequence_max_length\n",
    "  check_freq = args.check_freq\n",
    "\n",
    "  # input_size = output_size = args.input_size\n",
    "  mem_slot = args.mem_slot\n",
    "  mem_size = args.mem_size\n",
    "  read_heads = args.read_heads\n",
    "\n",
    "  print(\"batch_size:\",args.batch_size)\n",
    "  train_iter, val_iter, test_iter, vocab_size, text_field =get_babidata_task_etc(task,args.batch_size,sequence_max_length,6)\n",
    "  args.batch_size\n",
    "  if args.memory_type == 'dnc':\n",
    "    rnn = DNC(\n",
    "        #input_size=args.input_size,\n",
    "        input_size=vocab_size,\n",
    "        hidden_size=args.nhid,\n",
    "        rnn_type=args.rnn_type,\n",
    "        num_layers=args.nlayer,\n",
    "        num_hidden_layers=args.nhlayer,\n",
    "        dropout=args.dropout,\n",
    "        nr_cells=mem_slot,\n",
    "        cell_size=mem_size,\n",
    "        read_heads=read_heads,\n",
    "        gpu_id=args.cuda,\n",
    "        debug=args.visdom,\n",
    "        batch_first=True,\n",
    "        independent_linears=True)\n",
    "  #batchfirst\n",
    "  print(rnn)\n",
    "  # register_nan_checks(rnn)\n",
    "\n",
    "  if args.optim == 'adam':\n",
    "    optimizer = optim.Adam(rnn.parameters(), lr=args.lr, eps=1e-9, betas=[0.9, 0.98]) # 0.0001\n",
    "  elif args.optim == 'adamax':\n",
    "    optimizer = optim.Adamax(rnn.parameters(), lr=args.lr, eps=1e-9, betas=[0.9, 0.98]) # 0.0001\n",
    "  elif args.optim == 'rmsprop':\n",
    "    optimizer = optim.RMSprop(rnn.parameters(), lr=args.lr, momentum=0.9, eps=1e-10) # 0.0001\n",
    "  elif args.optim == 'sgd':\n",
    "    optimizer = optim.SGD(rnn.parameters(), lr=args.lr) # 0.01\n",
    "  elif args.optim == 'adagrad':\n",
    "    optimizer = optim.Adagrad(rnn.parameters(), lr=args.lr)\n",
    "  elif args.optim == 'adadelta':\n",
    "    optimizer = optim.Adadelta(rnn.parameters(), lr=args.lr)\n",
    "\n",
    "  criterion = nn.CrossEntropyLoss()\n",
    "  #criterion = my_criterion\n",
    "  save_dir=\"dnc_param\"\n",
    "  save_path=os.path.join(save_dir,\"task\"+str(task)+\".pth\")\n",
    "\n",
    "  iterations = args.iterations\n",
    "  summarize_freq = args.summarize_freq\n",
    "  print(\"summarize_freq:\",summarize_freq)\n",
    "  last_save_losses = []\n",
    "  last_val_losses =[]\n",
    "  val_acc=[]\n",
    "  val_bestacc=0\n",
    "  val_bestloss=0\n",
    "  bestepoch =0\n",
    "\n",
    "  if args.cuda != -1:\n",
    "    rnn = rnn.cuda(args.cuda)\n",
    "  \n",
    "  rnn.train()\n",
    "  (chx, mhx, rv) = (None, None, None)\n",
    "  for epoch in range(iterations + 1):\n",
    "    llprint(\"\\rIteration {ep}/{tot}\".format(ep=epoch, tot=iterations))\n",
    "    \n",
    "    #generate_data(batch_size, random_length, args.input_size, args.cuda)\n",
    "    for i,batch in enumerate(train_iter):\n",
    "      llprint(\"\\rbatch {bt}\".format(bt=i))\n",
    "      batch_size = batch.batch_size\n",
    "      train_x,train_y,ans_id =prep_data(batch,vocab_size)\n",
    "      #torch.autograd.set_detect_anomaly(True)\n",
    "      if train_x.size()[0]!=args.batch_size:continue\n",
    "      #if rnn.debug:\n",
    "      #  output, (chx, mhx, rv), v = rnn(train_x, (None, mhx, None), reset_experience=True, pass_through_memory=True)\n",
    "      #else:\n",
    "      output, (chx, mhx, rv) = rnn(train_x, (None, mhx, None), reset_experience=True, pass_through_memory=True)\n",
    "      \n",
    "      optimizer.zero_grad()\n",
    "      last_output =output[:,-1,:]\n",
    "      #print(\"last_output.size():\",last_output.size(),\" ans_id.size():\",ans_id.size())\n",
    "      #loss = criterion((last_output),train_y)\n",
    "      loss = criterion(last_output,ans_id)\n",
    "      if i==0:print(\"oneloss:\",loss.item())\n",
    "      loss.backward()\n",
    "      T.nn.utils.clip_grad_norm_(rnn.parameters(), args.clip)\n",
    "      optimizer.step()\n",
    "      loss_value = loss.item()\n",
    "      last_save_losses.append(loss_value)\n",
    "\n",
    "      mhx = { k : (v.detach() if isinstance(v, var) else v) for k, v in mhx.items() }#~~??\n",
    "\n",
    "    #T.nn.utils.clip_grad_norm_(rnn.parameters(), args.clip) ~~??\n",
    "\n",
    "    #validation\n",
    "    with torch.no_grad():\n",
    "      for i,batch in enumerate(val_iter):\n",
    "        #print(\"\\rIteration {ep}/{tot}\".format(ep=epoch, tot=iterations))\n",
    "        batch_size=batch.batch_size\n",
    "        val_x,val_y,val_ansid =prep_data(batch,vocab_size)\n",
    "        if val_x.size()[0]!=args.batch_size:continue\n",
    "        #print(\"valx.size():\",val_x.size(),\" valy.size():\",val_y.size())\n",
    "        output, (chx, mhx, rv) = rnn(val_x, (None, mhx, None), reset_experience=True, pass_through_memory=True)\n",
    "        last_output =output[:,-1,:]\n",
    "        optimizer.zero_grad()    \n",
    "        loss = criterion(last_output,val_ansid)\n",
    "        #loss = criterion((last_output),val_y)\n",
    "        loss_value = loss.item()\n",
    "        last_val_losses.append(loss_value)\n",
    "\n",
    "        pred_id = torch.argmax(last_output,1) #1D\n",
    "        pred_id = pred_id.cpu().numpy() # (batch_size, vocab_len)　のはず\n",
    "        val_ansid = val_ansid.cpu().numpy()\n",
    "        val_acc.append(((pred_id == val_ansid).sum()/ len(val_ansid) ))\n",
    "    \n",
    "    take_checkpoint = (epoch != 0) and (epoch % check_freq == 0)\n",
    "    increment_curriculum = (epoch != 0) and (epoch % args.curriculum_freq == 0)\n",
    "    take_checkpoint=False#~\n",
    "    increment_curriculum=False#~\n",
    "\n",
    "    # detach memory from graph\n",
    "    #~?mhx = { k : (v.detach() if isinstance(v, var) else v) for k, v in mhx.items() }\n",
    "\n",
    "    #last_save_losses.append(loss_value)\n",
    "\n",
    "    summarize = (epoch % summarize_freq == 0)\n",
    "    if summarize:\n",
    "      loss = np.mean(last_save_losses)\n",
    "      #llprint(\"\\n\\tAvg. Logistic Loss: %.4f\\n\" % (loss))\n",
    "      if np.isnan(loss):\n",
    "        raise Exception('nan Loss')\n",
    "      print(\"epoch:\",epoch,\" loss:\",loss)\n",
    "      val_loss = np.mean(last_val_losses)\n",
    "      print(\"    val_loss:\",val_loss)\n",
    "      mean_acc =np.mean(val_acc)\n",
    "      print(\"    val_acc:\",mean_acc)\n",
    "      if mean_acc>val_bestacc:\n",
    "        val_bestacc =mean_acc\n",
    "        val_bestloss=val_loss\n",
    "        bestepoch=epoch\n",
    "        torch.save(rnn.state_dict(), save_path)\n",
    "      last_save_losses = []\n",
    "      last_val_losses =[]\n",
    "      val_acc=[]\n",
    "\n",
    "    '''しばらくデバッグはしない\n",
    "    if summarize and rnn.debug:\n",
    "      loss = np.mean(last_save_losses)\n",
    "      last_save_losses = []\n",
    "      if args.memory_type == 'dnc':\n",
    "        viz.heatmap(\n",
    "            v['memory'],\n",
    "            opts=dict(\n",
    "                xtickstep=10,\n",
    "                ytickstep=2,\n",
    "                title='Memory, t: ' + str(epoch) + ', loss: ' + str(loss),\n",
    "                ylabel='layer * time',\n",
    "                xlabel='mem_slot * mem_size'\n",
    "            )\n",
    "        )\n",
    "      if args.memory_type == 'dnc':\n",
    "        viz.heatmap(\n",
    "            v['link_matrix'][-1].reshape(args.mem_slot, args.mem_slot),\n",
    "            opts=dict(\n",
    "                xtickstep=10,\n",
    "                ytickstep=2,\n",
    "                title='Link Matrix, t: ' + str(epoch) + ', loss: ' + str(loss),\n",
    "                ylabel='mem_slot',\n",
    "                xlabel='mem_slot'\n",
    "            )\n",
    "        )\n",
    "        viz.heatmap(\n",
    "            v['rev_link_matrix'][-1].reshape(args.mem_slot, -1),\n",
    "            opts=dict(\n",
    "                xtickstep=10,\n",
    "                ytickstep=2,\n",
    "                title='Reverse Link Matrix, t: ' + str(epoch) + ', loss: ' + str(loss),\n",
    "                ylabel='mem_slot',\n",
    "                xlabel='mem_slot'\n",
    "            )\n",
    "        )\n",
    "      elif args.memory_type == 'sdnc' or args.memory_type == 'dnc':\n",
    "        viz.heatmap(\n",
    "            v['precedence'],\n",
    "            opts=dict(\n",
    "                xtickstep=10,\n",
    "                ytickstep=2,\n",
    "                title='Precedence, t: ' + str(epoch) + ', loss: ' + str(loss),\n",
    "                ylabel='layer * time',\n",
    "                xlabel='mem_slot'\n",
    "            )\n",
    "        )\n",
    "      viz.heatmap(\n",
    "          v['read_weights'],\n",
    "          opts=dict(\n",
    "              xtickstep=10,\n",
    "              ytickstep=2,\n",
    "              title='Read Weights, t: ' + str(epoch) + ', loss: ' + str(loss),\n",
    "              ylabel='layer * time',\n",
    "              xlabel='nr_read_heads * mem_slot'\n",
    "          )\n",
    "      )\n",
    "      viz.heatmap(\n",
    "          v['write_weights'],\n",
    "          opts=dict(\n",
    "              xtickstep=10,\n",
    "              ytickstep=2,\n",
    "              title='Write Weights, t: ' + str(epoch) + ', loss: ' + str(loss),\n",
    "              ylabel='layer * time',\n",
    "              xlabel='mem_slot'\n",
    "          )\n",
    "      )\n",
    "      viz.heatmap(\n",
    "          v['usage_vector'] if args.memory_type == 'dnc' else v['usage'],\n",
    "          opts=dict(\n",
    "              xtickstep=10,\n",
    "              ytickstep=2,\n",
    "              title='Usage Vector, t: ' + str(epoch) + ', loss: ' + str(loss),\n",
    "              ylabel='layer * time',\n",
    "              xlabel='mem_slot'\n",
    "          )\n",
    "      )\n",
    "    '''\n",
    "    if increment_curriculum:\n",
    "      sequence_max_length = sequence_max_length + args.curriculum_increment\n",
    "      print(\"Increasing max length to \" + str(sequence_max_length))\n",
    "\n",
    "    if take_checkpoint:\n",
    "      llprint(\"\\nSaving Checkpoint ... \"),\n",
    "      check_ptr = os.path.join(ckpts_dir, 'step_{}.pth'.format(epoch))\n",
    "      cur_weights = rnn.state_dict()\n",
    "      T.save(cur_weights, check_ptr)\n",
    "      llprint(\"Done!\\n\")\n",
    "\n",
    "  #Test\n",
    "  print(\"=====TEST=====\")\n",
    "  last_save_losses=[]\n",
    "  accuracy_rates =[]\n",
    "  test_loss=0\n",
    "  test_acc=0\n",
    "\n",
    "  rnn.load_state_dict(torch.load(save_path))\n",
    "  rnn.eval()\n",
    "\n",
    "  with torch.no_grad():\n",
    "    for i,batch in enumerate(test_iter):\n",
    "      llprint(\"\\nIteration %d/%d\" % (i, iterations))\n",
    "      # We test now the learned generalization using sequence_max_length examples\n",
    "      batch_size=batch.batch_size\n",
    "      test_x,test_y,ans_id =prep_data(batch,vocab_size)\n",
    "      if val_x.size()[0]!=args.batch_size:continue\n",
    "      if rnn.debug:\n",
    "        output, (chx, mhx, rv), v = rnn(test_x, (None, mhx, None), reset_experience=True, pass_through_memory=True)\n",
    "      else:\n",
    "        output, (chx, mhx, rv) = rnn(test_x, (None, mhx, None), reset_experience=True, pass_through_memory=True)\n",
    "      last_output =output[:,-1,:]\n",
    "\n",
    "      optimizer.zero_grad()\n",
    "      loss = criterion(last_output,ans_id)\n",
    "      loss_value = loss.item()\n",
    "      last_save_losses.append(loss_value)\n",
    "      pred_id = torch.argmax(last_output,1) #1D\n",
    "      pred_id = pred_id.cpu().numpy() # (batch_size, vocab_len)　のはず\n",
    "      ans_id = ans_id.cpu().numpy()\n",
    "      accuracy_rates.append(((pred_id == ans_id).sum()/ len(ans_id) ))\n",
    "\n",
    "      \"\"\"try:\n",
    "        print(\"\\nReal value: \", ' = ' + str(int(target_output[0])))\n",
    "        print(\"Predicted:  \", ' = ' + str(int(output // 1)) + \" [\" + str(output) + \"]\")\n",
    "      except Exception as e:\n",
    "        pass\"\"\"\n",
    "\n",
    "    test_loss = np.mean(last_save_losses)\n",
    "    test_acc =np.mean(accuracy_rates)\n",
    "    print(\" loss:\",test_loss)\n",
    "    print(\"accuracy_rate:\",test_acc)\n",
    "\n",
    "  return {\"task\":task,\"best_epoch\":bestepoch,\n",
    "  \"best_val_loss\":val_bestloss,\"best_val_acc\":val_bestacc,\n",
    "  \"test_loss\":test_loss,\"test_acc\":test_acc\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5233372e-427d-463d-89fc-3ddcc6f008f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========task: 1\n",
      "batch_size: 50\n",
      "VOCAB LEN PLUS: 21\n",
      "\n",
      "----------------------------------------\n",
      "DNC(21, 256, nr_cells=256, read_heads=4, cell_size=64, gpu_id=0, independent_linears=True)\n",
      "DNC(\n",
      "  (lstm_layer_0): LSTM(277, 256, num_layers=2, batch_first=True)\n",
      "  (rnn_layer_memory_shared): Memory(\n",
      "    (read_keys_transform): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (read_strengths_transform): Linear(in_features=256, out_features=4, bias=True)\n",
      "    (write_key_transform): Linear(in_features=256, out_features=64, bias=True)\n",
      "    (write_strength_transform): Linear(in_features=256, out_features=1, bias=True)\n",
      "    (erase_vector_transform): Linear(in_features=256, out_features=64, bias=True)\n",
      "    (write_vector_transform): Linear(in_features=256, out_features=64, bias=True)\n",
      "    (free_gates_transform): Linear(in_features=256, out_features=4, bias=True)\n",
      "    (allocation_gate_transform): Linear(in_features=256, out_features=1, bias=True)\n",
      "    (write_gate_transform): Linear(in_features=256, out_features=1, bias=True)\n",
      "    (read_modes_transform): Linear(in_features=256, out_features=12, bias=True)\n",
      "  )\n",
      "  (output): Linear(in_features=512, out_features=21, bias=True)\n",
      ")\n",
      "----------------------------------------\n",
      "\n",
      "summarize_freq: 10\n",
      "batch 0on 0/1000"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 14.00 MiB (GPU 0; 10.92 GiB total capacity; 6.50 GiB already allocated; 9.12 MiB free; 7.21 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [16], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m state\u001b[38;5;241m=\u001b[39m[]\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m21\u001b[39m):\n\u001b[0;32m----> 3\u001b[0m     state \u001b[38;5;241m.\u001b[39mappend(\u001b[43mmain_dnc_babi\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(pd\u001b[38;5;241m.\u001b[39mDataFrame(state))\n",
      "Cell \u001b[0;32mIn [13], line 86\u001b[0m, in \u001b[0;36mmain_dnc_babi\u001b[0;34m(task)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m train_x\u001b[38;5;241m.\u001b[39msize()[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m!=\u001b[39margs\u001b[38;5;241m.\u001b[39mbatch_size:\u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;66;03m#if rnn.debug:\u001b[39;00m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;66;03m#  output, (chx, mhx, rv), v = rnn(train_x, (None, mhx, None), reset_experience=True, pass_through_memory=True)\u001b[39;00m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;66;03m#else:\u001b[39;00m\n\u001b[0;32m---> 86\u001b[0m output, (chx, mhx, rv) \u001b[38;5;241m=\u001b[39m \u001b[43mrnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmhx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset_experience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpass_through_memory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     88\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     89\u001b[0m last_output \u001b[38;5;241m=\u001b[39moutput[:,\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,:]\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:727\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_slow_forward(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    726\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 727\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    728\u001b[0m \u001b[39mfor\u001b[39;00m hook \u001b[39min\u001b[39;00m itertools\u001b[39m.\u001b[39mchain(\n\u001b[1;32m    729\u001b[0m         _global_forward_hooks\u001b[39m.\u001b[39mvalues(),\n\u001b[1;32m    730\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks\u001b[39m.\u001b[39mvalues()):\n\u001b[1;32m    731\u001b[0m     hook_result \u001b[39m=\u001b[39m hook(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m, result)\n",
      "File \u001b[0;32m/work/old_workspace/dnc_shakyou/dnc.ipynb:285\u001b[0m, in \u001b[0;36mDNC.forward\u001b[0;34m(self, input, hx, reset_experience, pass_through_memory)\u001b[0m\n\u001b[1;32m    283\u001b[0m m \u001b[39m=\u001b[39m mem_hidden \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mshare_memory \u001b[39melse\u001b[39;00m mem_hidden[layer]\n\u001b[1;32m    284\u001b[0m \u001b[39m# pass through controller\u001b[39;00m\n\u001b[0;32m--> 285\u001b[0m outs[time], (chx,m,read_vectors) \u001b[39m=\u001b[39m                     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_layer_forward(inputs[time],layer,(chx,m), pass_through_memory)\n\u001b[1;32m    287\u001b[0m \u001b[39m#debug memory\u001b[39;00m\n\u001b[1;32m    288\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdebug:\n",
      "File \u001b[0;32m/work/old_workspace/dnc_shakyou/dnc.ipynb:234\u001b[0m, in \u001b[0;36mDNC._layer_forward\u001b[0;34m(self, input, layer, hx, pass_through_memory)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[39mif\u001b[39;00m pass_through_memory:\n\u001b[1;32m    233\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mshare_memory:\n\u001b[0;32m--> 234\u001b[0m         read_vecs, mhx \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmemories[\u001b[39m0\u001b[39;49m](ξ,mhx)\n\u001b[1;32m    235\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    236\u001b[0m         read_vecs, mhx \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmemories[layer](ξ,mhx)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:727\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_slow_forward(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    726\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 727\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    728\u001b[0m \u001b[39mfor\u001b[39;00m hook \u001b[39min\u001b[39;00m itertools\u001b[39m.\u001b[39mchain(\n\u001b[1;32m    729\u001b[0m         _global_forward_hooks\u001b[39m.\u001b[39mvalues(),\n\u001b[1;32m    730\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks\u001b[39m.\u001b[39mvalues()):\n\u001b[1;32m    731\u001b[0m     hook_result \u001b[39m=\u001b[39m hook(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m, result)\n",
      "File \u001b[0;32m/work/old_workspace/dnc_shakyou/memory.ipynb:280\u001b[0m, in \u001b[0;36mMemory.forward\u001b[0;34m(self, ξ, hidden)\u001b[0m\n\u001b[1;32m    277\u001b[0m   \u001b[39m# read modes (b * 3*r)\u001b[39;00m\n\u001b[1;32m    278\u001b[0m   read_modes \u001b[39m=\u001b[39m σ(ξ[:, r \u001b[39m*\u001b[39m w \u001b[39m+\u001b[39m \u001b[39m2\u001b[39m \u001b[39m*\u001b[39m r \u001b[39m+\u001b[39m \u001b[39m3\u001b[39m \u001b[39m*\u001b[39m w \u001b[39m+\u001b[39m \u001b[39m3\u001b[39m: r \u001b[39m*\u001b[39m w \u001b[39m+\u001b[39m \u001b[39m5\u001b[39m \u001b[39m*\u001b[39m r \u001b[39m+\u001b[39m \u001b[39m3\u001b[39m \u001b[39m*\u001b[39m w \u001b[39m+\u001b[39m \u001b[39m3\u001b[39m]\u001b[39m.\u001b[39mcontiguous()\u001b[39m.\u001b[39mview(b, r, \u001b[39m3\u001b[39m), \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m--> 280\u001b[0m hidden \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mwrite(write_key, write_vector, erase_vector, free_gates,\n\u001b[1;32m    281\u001b[0m                     read_strengths, write_strength, write_gate, allocation_gate, hidden)\n\u001b[1;32m    282\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mread(read_keys, read_strengths, read_modes, hidden)\n",
      "File \u001b[0;32m/work/old_workspace/dnc_shakyou/memory.ipynb:183\u001b[0m, in \u001b[0;36mMemory.write\u001b[0;34m(self, write_key, write_vector, erase_vector, free_gates, read_strengths, write_strength, write_gate, allocation_gate, hidden)\u001b[0m\n\u001b[1;32m    180\u001b[0m hidden[\u001b[39m'\u001b[39m\u001b[39mmemory\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m hidden[\u001b[39m'\u001b[39m\u001b[39mmemory\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m+\u001b[39m         T\u001b[39m.\u001b[39mbmm(hidden[\u001b[39m'\u001b[39m\u001b[39mwrite_weights\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mtranspose(\u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m), write_vector)\n\u001b[1;32m    182\u001b[0m \u001b[39m# update link_matrix\u001b[39;00m\n\u001b[0;32m--> 183\u001b[0m hidden[\u001b[39m'\u001b[39m\u001b[39mlink_matrix\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_link_matrix(\n\u001b[1;32m    184\u001b[0m     hidden[\u001b[39m'\u001b[39;49m\u001b[39mlink_matrix\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    185\u001b[0m     hidden[\u001b[39m'\u001b[39;49m\u001b[39mwrite_weights\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    186\u001b[0m     hidden[\u001b[39m'\u001b[39;49m\u001b[39mprecedence\u001b[39;49m\u001b[39m'\u001b[39;49m]\n\u001b[1;32m    187\u001b[0m )\n\u001b[1;32m    188\u001b[0m hidden[\u001b[39m'\u001b[39m\u001b[39mprecedence\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mupdate_precedence(hidden[\u001b[39m'\u001b[39m\u001b[39mprecedence\u001b[39m\u001b[39m'\u001b[39m], hidden[\u001b[39m'\u001b[39m\u001b[39mwrite_weights\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m    190\u001b[0m \u001b[39mreturn\u001b[39;00m hidden\n",
      "File \u001b[0;32m/work/old_workspace/dnc_shakyou/memory.ipynb:141\u001b[0m, in \u001b[0;36mMemory.get_link_matrix\u001b[0;34m(self, link_matrix, write_weights, precedence)\u001b[0m\n\u001b[1;32m    138\u001b[0m prev_scale \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m \u001b[39m-\u001b[39m write_weights_i \u001b[39m-\u001b[39m write_weights_j\n\u001b[1;32m    139\u001b[0m new_link_matrix \u001b[39m=\u001b[39m write_weights_i \u001b[39m*\u001b[39m precedence\n\u001b[0;32m--> 141\u001b[0m link_matrix \u001b[39m=\u001b[39m prev_scale \u001b[39m*\u001b[39;49m link_matrix \u001b[39m+\u001b[39;49m new_link_matrix\n\u001b[1;32m    142\u001b[0m \u001b[39m# trick to delete diag elems\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mI\u001b[39m.\u001b[39mexpand_as(link_matrix) \u001b[39m*\u001b[39m link_matrix\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 14.00 MiB (GPU 0; 10.92 GiB total capacity; 6.50 GiB already allocated; 9.12 MiB free; 7.21 GiB reserved in total by PyTorch)"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "state=[]\n",
    "for task in range(1,21):\n",
    "    state .append(main_dnc_babi(task))\n",
    "\n",
    "print(pd.DataFrame(state))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "085d3ce7",
   "metadata": {},
   "source": [
    "detachのとことかまだよくわかってない  \n",
    "lstmはモデルの外に隠れ状態を出していなかった。いや出力として出てくるんだけど、モデルの入力として渡さない。この場合detachをしなくて問題なかった  \n",
    "こちらではモデルの出力として出したものを、次に入力に入れる。この場合計算グラフをさかのぼっていく？でも↑の場合だと遡る？それともライブラリの方で値引き継ぎとdetachをする？  \n",
    "あとこっちの場合、chxとかを入力にしなくてもいいのか気になる"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce411fc4",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
