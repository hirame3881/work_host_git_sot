{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/work/my_modified_ntm', '/usr/lib/python38.zip', '/usr/lib/python3.8', '/usr/lib/python3.8/lib-dynload', '', '/usr/local/lib/python3.8/dist-packages', '/usr/lib/python3/dist-packages', '/work/my_modified_ntm/bgavDNC_src']\n",
      "['/work/my_modified_ntm', '/usr/lib/python38.zip', '/usr/lib/python3.8', '/usr/lib/python3.8/lib-dynload', '', '/usr/local/lib/python3.8/dist-packages', '/usr/lib/python3/dist-packages', '/work/my_modified_ntm/bgavDNC_src', '/work/my_modified_ntm/bgavDNC_src']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.path)\n",
    "sys.path.append(\"/work/my_modified_ntm/bgavDNC_src\")\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from task_implementations.bAbI.bAbI import *\n",
    "from utils import project_path, init_wrapper\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded task\n"
     ]
    }
   ],
   "source": [
    "task = bAbITask(os.path.join(\"tasks_1-20_v1-2\", \"en-10k\"))\n",
    "print(\"Loaded task\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded task\n"
     ]
    }
   ],
   "source": [
    "task = bAbITask(os.path.join(\"tasks_1-20_v1-2\", \"en-10k\"))\n",
    "print(\"Loaded task\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160\n",
      "{0: '-', 1: '*', 2: 'mary', 3: 'is', 4: 'no', 5: 'longer', 6: 'in', 7: 'the', 8: 'bedroom', 9: '.', 10: 'daniel', 11: 'moved', 12: 'to', 13: 'hallway', 14: '?', 15: 'sandra', 16: 'bathroom', 17: 'not', 18: 'office', 19: 'went', 20: 'john', 21: 'kitchen', 22: 'travelled', 23: 'back', 24: 'garden', 25: 'yes', 26: 'journeyed', 27: 'sumit', 28: 'tired', 29: 'where', 30: 'will', 31: 'go', 32: 'why', 33: 'did', 34: 'grabbed', 35: 'pajamas', 36: 'there', 37: 'get', 38: 'yann', 39: 'bored', 40: 'jason', 41: 'thirsty', 42: 'got', 43: 'football', 44: 'antoine', 45: 'milk', 46: 'hungry', 47: 'took', 48: 'apple', 49: 'picked', 50: 'up', 51: 'bill', 52: 'gave', 53: 'fred', 54: 'what', 55: 'give', 56: 'handed', 57: 'jeff', 58: 'who', 59: 'received', 60: 'left', 61: 'passed', 62: 'put', 63: 'down', 64: 'dropped', 65: 'discarded', 66: 'carrying', 67: 'nothing', 68: 'how', 69: 'many', 70: 'objects', 71: 'one', 72: 'none', 73: 'two', 74: 'three', 75: 'cinema', 76: 'yesterday', 77: 'julie', 78: 'school', 79: 'this', 80: 'morning', 81: 'park', 82: 'was', 83: 'before', 84: 'afternoon', 85: 'evening', 86: 'either', 87: 'or', 88: 'maybe', 89: 'after', 90: 'that', 91: 'she', 92: 'afterwards', 93: 'he', 94: 'following', 95: 'then', 96: 'wolves', 97: 'are', 98: 'afraid', 99: 'of', 100: 'mice', 101: 'sheep', 102: 'winona', 103: 'a', 104: 'cats', 105: 'jessica', 106: 'mouse', 107: 'emily', 108: 'cat', 109: 'gertrude', 110: 'wolf', 111: 'north', 112: 'south', 113: 'west', 114: 'east', 115: 'suitcase', 116: 'fits', 117: 'inside', 118: 'box', 119: 'chocolate', 120: 'container', 121: 'bigger', 122: 'than', 123: 'chocolates', 124: 'chest', 125: 'does', 126: 'fit', 127: 'and', 128: 'they', 129: 'triangle', 130: 'above', 131: 'pink', 132: 'rectangle', 133: 'blue', 134: 'square', 135: 'right', 136: 'below', 137: 'red', 138: 'sphere', 139: 'yellow', 140: 'lily', 141: 'frog', 142: 'bernhard', 143: 'green', 144: 'brian', 145: 'lion', 146: 'white', 147: 'julius', 148: 'swan', 149: 'greg', 150: 'color', 151: 'rhino', 152: 'gray', 153: 'do', 154: 'you', 155: 'from', 156: 's', 157: 'e', 158: 'n', 159: 'w'}\n"
     ]
    }
   ],
   "source": [
    "print(task.vector_size)\n",
    "print(task.ind_to_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[None, None, 160]\n",
      "[None, None, 1]\n"
     ]
    }
   ],
   "source": [
    "print(task.x_shape)\n",
    "print(task.mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['/work/my_modified_ntm/bgavDNC_src/task_implementations/bAbI/tasks_1-20_v1-2/en-10k/qa9_simple-negation_train.txt', '/work/my_modified_ntm/bgavDNC_src/task_implementations/bAbI/tasks_1-20_v1-2/en-10k/qa20_agents-motivations_train.txt', '/work/my_modified_ntm/bgavDNC_src/task_implementations/bAbI/tasks_1-20_v1-2/en-10k/qa5_three-arg-relations_train.txt', '/work/my_modified_ntm/bgavDNC_src/task_implementations/bAbI/tasks_1-20_v1-2/en-10k/qa14_time-reasoning_train.txt', '/work/my_modified_ntm/bgavDNC_src/task_implementations/bAbI/tasks_1-20_v1-2/en-10k/qa10_indefinite-knowledge_train.txt', '/work/my_modified_ntm/bgavDNC_src/task_implementations/bAbI/tasks_1-20_v1-2/en-10k/qa11_basic-coreference_train.txt', '/work/my_modified_ntm/bgavDNC_src/task_implementations/bAbI/tasks_1-20_v1-2/en-10k/qa1_single-supporting-fact_train.txt', '/work/my_modified_ntm/bgavDNC_src/task_implementations/bAbI/tasks_1-20_v1-2/en-10k/qa3_three-supporting-facts_train.txt', '/work/my_modified_ntm/bgavDNC_src/task_implementations/bAbI/tasks_1-20_v1-2/en-10k/qa4_two-arg-relations_train.txt', '/work/my_modified_ntm/bgavDNC_src/task_implementations/bAbI/tasks_1-20_v1-2/en-10k/qa13_compound-coreference_train.txt', '/work/my_modified_ntm/bgavDNC_src/task_implementations/bAbI/tasks_1-20_v1-2/en-10k/qa2_two-supporting-facts_train.txt', '/work/my_modified_ntm/bgavDNC_src/task_implementations/bAbI/tasks_1-20_v1-2/en-10k/qa17_positional-reasoning_train.txt', '/work/my_modified_ntm/bgavDNC_src/task_implementations/bAbI/tasks_1-20_v1-2/en-10k/qa16_basic-induction_train.txt', '/work/my_modified_ntm/bgavDNC_src/task_implementations/bAbI/tasks_1-20_v1-2/en-10k/qa15_basic-deduction_train.txt', '/work/my_modified_ntm/bgavDNC_src/task_implementations/bAbI/tasks_1-20_v1-2/en-10k/qa7_counting_train.txt', '/work/my_modified_ntm/bgavDNC_src/task_implementations/bAbI/tasks_1-20_v1-2/en-10k/qa8_lists-sets_train.txt', '/work/my_modified_ntm/bgavDNC_src/task_implementations/bAbI/tasks_1-20_v1-2/en-10k/qa6_yes-no-questions_train.txt', '/work/my_modified_ntm/bgavDNC_src/task_implementations/bAbI/tasks_1-20_v1-2/en-10k/qa12_conjunction_train.txt', '/work/my_modified_ntm/bgavDNC_src/task_implementations/bAbI/tasks_1-20_v1-2/en-10k/qa19_path-finding_train.txt', '/work/my_modified_ntm/bgavDNC_src/task_implementations/bAbI/tasks_1-20_v1-2/en-10k/qa18_size-reasoning_train.txt'])\n"
     ]
    }
   ],
   "source": [
    "print(task.x_train_stories.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "(200,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_46505/1198921949.py:3: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  xarr=np.array(xlis)\n"
     ]
    }
   ],
   "source": [
    "xlis=task.y_test_stories[\"/work/my_modified_ntm/bgavDNC_src/task_implementations/bAbI/tasks_1-20_v1-2/en-10k/qa8_lists-sets_test.txt\"]\n",
    "print(type(xlis))\n",
    "xarr=np.array(xlis)\n",
    "print(xarr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mary', 'got', 'the', 'milk', 'there', '.', 'john', 'moved', 'to', 'the', 'bedroom', '.', 'what', 'is', 'mary', 'carrying', '?', '-', 'john', 'picked', 'up', 'the', 'football', 'there', '.', 'john', 'journeyed', 'to', 'the', 'bathroom', '.', 'what', 'is', 'john', 'carrying', '?', '-', 'john', 'went', 'to', 'the', 'garden', '.', 'daniel', 'went', 'back', 'to', 'the', 'hallway', '.', 'what', 'is', 'john', 'carrying', '?', '-', 'john', 'went', 'back', 'to', 'the', 'bathroom', '.', 'mary', 'went', 'to', 'the', 'office', '.', 'sandra', 'went', 'back', 'to', 'the', 'kitchen', '.', 'mary', 'travelled', 'to', 'the', 'hallway', '.', 'john', 'travelled', 'to', 'the', 'bedroom', '.', 'john', 'picked', 'up', 'the', 'apple', 'there', '.', 'what', 'is', 'john', 'carrying', '?', '-', '-', 'sandra', 'travelled', 'to', 'the', 'bedroom', '.', 'sandra', 'journeyed', 'to', 'the', 'kitchen', '.', 'what', 'is', 'john', 'carrying', '?', '-', '-']\n",
      "['mary', 'got', 'the', 'milk', 'there', '.', 'john', 'moved', 'to', 'the', 'bedroom', '.', 'what', 'is', 'mary', 'carrying', '?', 'milk', 'john', 'picked', 'up', 'the', 'football', 'there', '.', 'john', 'journeyed', 'to', 'the', 'bathroom', '.', 'what', 'is', 'john', 'carrying', '?', 'football', 'john', 'went', 'to', 'the', 'garden', '.', 'daniel', 'went', 'back', 'to', 'the', 'hallway', '.', 'what', 'is', 'john', 'carrying', '?', 'football', 'john', 'went', 'back', 'to', 'the', 'bathroom', '.', 'mary', 'went', 'to', 'the', 'office', '.', 'sandra', 'went', 'back', 'to', 'the', 'kitchen', '.', 'mary', 'travelled', 'to', 'the', 'hallway', '.', 'john', 'travelled', 'to', 'the', 'bedroom', '.', 'john', 'picked', 'up', 'the', 'apple', 'there', '.', 'what', 'is', 'john', 'carrying', '?', 'football', 'apple', 'sandra', 'travelled', 'to', 'the', 'bedroom', '.', 'sandra', 'journeyed', 'to', 'the', 'kitchen', '.', 'what', 'is', 'john', 'carrying', '?', 'football', 'apple']\n"
     ]
    }
   ],
   "source": [
    "def idlist_to_word(lis):\n",
    "    return [task.ind_to_word[elm] for elm in lis]\n",
    "print(idlist_to_word( task.x_test_stories[\"/work/my_modified_ntm/bgavDNC_src/task_implementations/bAbI/tasks_1-20_v1-2/en-10k/qa8_lists-sets_test.txt\"][0] ))\n",
    "print(idlist_to_word( xlis[0]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[98, 102, 113]\n",
      "(3, 113, 1)\n",
      "160 (3, 113, 160) (3, 113, 160)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cost_value=999\n",
    "batch_size=3\n",
    "data_batch, seqlen, m = task.generate_data(cost=cost_value, batch_size=batch_size, train=True)\n",
    "print(seqlen)\n",
    "print(m.shape)\n",
    "print(task.vector_size,data_batch[0].shape,data_batch[1].shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "<class 'tuple'>\n",
      "2\n",
      "[[20, 22, 12, 7, 13, 9, 2, 26, 12, 7, 16, 9, 29, 3, 20, 14, 0, 10, 19, 23, 12, 7, 16, 9, 20, 11, 12, 7, 8, 9, 29, 3, 2, 14, 0, 20, 19, 12, 7, 13, 9, 15, 26, 12, 7, 21, 9, 29, 3, 15, 14, 0, 15, 22, 12, 7, 13, 9, 20, 19, 12, 7, 24, 9, 29, 3, 15, 14, 0, 15, 19, 23, 12, 7, 16, 9, 15, 11, 12, 7, 21, 9, 29, 3, 15, 14, 0], [15, 22, 12, 7, 21, 9, 15, 22, 12, 7, 13, 9, 29, 3, 15, 14, 0, 2, 19, 12, 7, 16, 9, 15, 11, 12, 7, 24, 9, 29, 3, 15, 14, 0, 15, 22, 12, 7, 18, 9, 10, 26, 12, 7, 13, 9, 29, 3, 10, 14, 0, 10, 26, 12, 7, 18, 9, 20, 11, 12, 7, 13, 9, 29, 3, 15, 14, 0, 20, 22, 12, 7, 16, 9, 20, 26, 12, 7, 18, 9, 29, 3, 10, 14, 0]]\n"
     ]
    }
   ],
   "source": [
    "#test\n",
    "num_tasks = len(task.x_test_stories)\n",
    "print(num_tasks)\n",
    "for (inp,output) in zip(task.x_test_stories.items(), task.y_test_stories.items()):\n",
    "    #inp, out　どちらも(key,value) のタプルっぽい。key=storyごとにforで回す　forのひとつひとつは1key= 1task_type\n",
    "    print(type(inp))\n",
    "    print(len(inp))\n",
    "    print(inp[1][:2])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4576, 0.4576, 0.0619, 0.0228]], dtype=torch.float64)\n",
      "tensor([[0.3012, 0.3012, 0.2027, 0.1950]], dtype=torch.float64)\n",
      "tensor(0.7817, dtype=torch.float64) tensor(1.2001, dtype=torch.float64)\n",
      "tensor([[0.4676, 0.4676, 0.0719, 0.0328]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "intlis=torch.tensor([[3,3,1,0]],dtype=float)\n",
    "soft1=nn.functional.softmax(intlis,dim=1)\n",
    "soft2=nn.functional.softmax(soft1,dim=1)\n",
    "print(soft1)\n",
    "print(soft2)\n",
    "label=torch.tensor([1])\n",
    "cros=nn.CrossEntropyLoss()\n",
    "loss1=cros(intlis,label)\n",
    "loss2=cros(soft1,label)\n",
    "print(loss1,loss2)\n",
    "print(soft1+1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.6265e+00, 1.1144e-01, 1.3619e-04], dtype=torch.float64)\n",
      "tensor(0.5794, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "testints=torch.tensor([[1,2,1,0],\n",
    "                        [1,4,0,1],\n",
    "                        [0,0,10,0]],\n",
    "                        dtype=float)\n",
    "labels=torch.tensor([0,1,2]) # bad, good, great\n",
    "cross_nored=nn.CrossEntropyLoss(reduction='none')\n",
    "cros=nn.CrossEntropyLoss()\n",
    "print(cross_nored(testints,labels))\n",
    "print(cros(testints, labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mycross_OH_3Dto3D(input, target, reduction='mean'):\n",
    "    if reduction!=\"mean\": raise ValueError('reduction is not implemented yet')\n",
    "    if (input.dim()!=3) or (target.dim()!=3): raise ValueError('invalid dim')\n",
    "    ls_input=nn.functional.log_softmax(input, 2)\n",
    "    nll=-1*torch.einsum( 'blf,blf->bl',ls_input,target) \n",
    "    #nll=torch.mean(nll,dim=1)\n",
    "    return nll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 3\n",
      "torch.float64 torch.float64\n",
      "tensor([[1.6265e+00, 1.1144e-01, 1.3619e-04]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "testints3=torch.tensor([[[1,2,1,0],\n",
    "                        [1,4,0,1],\n",
    "                        [0,0,10,0]]],\n",
    "                        dtype=float)\n",
    "labels3=torch.tensor([[0,1,2]]) # bad, good, great\n",
    "labels3_onehot=nn.functional.one_hot(labels3,num_classes=4).to(torch.float64)\n",
    "print(testints3.dim(),labels3_onehot.dim())\n",
    "print(testints3.dtype,labels3_onehot.dtype)\n",
    "print(mycross_OH_3Dto3D(testints3,labels3_onehot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_masked_mean(loss,mask):\n",
    "    masked = loss * mask[:, :, 0]\n",
    "    mask_batchs =torch.sum(mask[:,:,0],dim=1)\n",
    "    return torch.mean(torch.sum(masked,dim=1)/ mask_batchs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 7, 4]) torch.Size([2, 7]) torch.Size([2, 7, 4]) torch.Size([2, 7, 1])\n",
      "tensor([[1.6265e+00, 1.1144e-01, 1.3619e-04, 1.0000e+01, 1.0000e+01, 1.0000e+01,\n",
      "         1.0000e+01],\n",
      "        [1.6265e+00, 1.1144e-01, 1.3619e-04, 1.0000e+01, 1.0000e+01, 1.0000e+01,\n",
      "         1.0000e+01]], dtype=torch.float64)\n",
      "tensor([[1.6265e+00, 1.1144e-01, 1.3619e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00],\n",
      "        [0.0000e+00, 1.1144e-01, 1.3619e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00]], dtype=torch.float64)\n",
      "tensor(0.1321, dtype=torch.float64)\n",
      "tensor(0.3176, dtype=torch.float64)\n",
      "tensor([3, 2])\n",
      "tensor([1.7381, 0.1116], dtype=torch.float64)\n",
      "tensor([0.5794, 0.0558], dtype=torch.float64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.3176, dtype=torch.float64)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#mask test!!!\n",
    "noisedints=torch.tensor([[[1,2,1,0],\n",
    "                        [1,4,0,1],\n",
    "                        [0,0,10,0],\n",
    "                        [10,0,0,0],[0,10,0,0],[0,0,10,0],[10,0,0,0]],\n",
    "                        [[1,2,1,0],\n",
    "                        [1,4,0,1],\n",
    "                        [0,0,10,0],\n",
    "                        [10,0,0,0],[0,10,0,0],[0,0,10,0],[10,0,0,0]]],\n",
    "                        dtype=float)\n",
    "noised_labels=torch.tensor([[0,1,2,3,3,3,3],[0,1,2,3,3,3,3]])\n",
    "noised_onehot=nn.functional.one_hot(noised_labels)\n",
    "mask=torch.tensor([[[1],[1],[1],[0],[0],[0],[0]],[[0],[1],[1],[0],[0],[0],[0]]])\n",
    "print(noisedints.size(), noised_labels.size(), noised_onehot.size(),mask.size())\n",
    "\n",
    "loss =mycross_OH_3Dto3D(noisedints,noised_onehot.to(torch.float64))\n",
    "print(loss)\n",
    "\n",
    "masked = loss * mask[:, :, 0]\n",
    "print(masked) # == cros\n",
    "print(torch.mean(masked))\n",
    "\n",
    "print(my_masked_mean(loss,mask))\n",
    "mask_batchs=torch.sum(mask[:,:,0],dim=1)\n",
    "print(mask_batchs)\n",
    "print(torch.sum(masked,dim=1))\n",
    "print(torch.sum(masked,dim=1)/ mask_batchs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 7])"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 0, 0],\n",
      "        [0, 1, 0],\n",
      "        [0, 0, 1]])\n"
     ]
    }
   ],
   "source": [
    "print(nn.functional.one_hot(labels))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
