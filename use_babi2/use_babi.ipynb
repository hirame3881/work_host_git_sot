{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "from io import open\n",
    "import inspect\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torchtext\n",
    "from torchtext.datasets import BABI20\n",
    "from torchtext.data import Dataset, Field, Example, Iterator\n",
    "\n",
    "import argparse\n",
    "from torchtext import datasets\n",
    "from torchtext.datasets.babi import BABI20Field\n",
    "#from models.UTransformer import BabiUTransformer\n",
    "#from models.common_layer import NoamOpt\n",
    "import torch.nn as nn\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__init_\n",
    "only_supporting（=False）は、(substory, query-\"?\", answer)のsubstory部分で、\n",
    "story行は一文まるごと保存　query-ans行は　supportung factをすべて抽出して\n",
    "True : substory= supporting story　の集まり\n",
    "False : substory= 全story\n",
    "でtrueにしてしまうと、storyのうちsupporting factのところしかstoryとして返さない\n",
    "\n",
    ".splits\n",
    "task=1, joint=False, tenK=False, only_supporting=False, train=None, validation=None, test=None\n",
    "en-valid-10kを見る\n",
    "joint=Trueで、全タスクを一つのtxtにまとめて学習する\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Mary', ' ', 'moved', ' ', 'to', ' ', 'the', ' ', '', ' ', 'bathroom', '.', '']\n",
      "['mary', 'moved', 'to', 'the', 'bathroom', '.']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "SPLIT_RE = re.compile('(\\W)+?')\n",
    "sentence =\"Mary moved to the  bathroom.\"\n",
    "print(re.split(SPLIT_RE, sentence))\n",
    "SPLIT_RE\n",
    "print([token.strip().lower() for token in re.split(SPLIT_RE, sentence) if token.strip()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_babidata(config):\n",
    "    \"\"\"(batch_size=config.batch_size, \n",
    "                                                            root='.data', \n",
    "                                                            memory_size=70, \n",
    "                                                            task=config.task, \n",
    "                                                            joint=False,\n",
    "                                                            tenK=False, \n",
    "                                                            only_supporting=False, \n",
    "                                                            sort=False, \n",
    "                                                            shuffle=True)\"\"\"\n",
    "    text = BABI20Field(50)\n",
    "    train, val, test = datasets.BABI20.splits(text, root='.data', task=2, joint=False,\n",
    "                                            tenK=True, only_supporting=False)\n",
    "    text.build_vocab(train)\n",
    "    vocab_len1 = len(text.vocab.freqs) \n",
    "    print(\"VOCAB LEN:\",vocab_len1 )\n",
    "    train_iter,val_iter,test_iter = Iterator.splits((train, val, test),batch_size=32)\n",
    "    return train_iter, val_iter, test_iter,vocab_len1+1,text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_config(argtext):\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--cuda\", action=\"store_true\")\n",
    "    parser.add_argument(\"--save_path\", type=str, default=\"save/\")\n",
    "    parser.add_argument(\"--task\", type=int, default=1)\n",
    "    parser.add_argument(\"--run_avg\", type=int, default=10)\n",
    "    parser.add_argument(\"--heads\", type=int, default=2)\n",
    "    parser.add_argument(\"--depth\", type=int, default=128)\n",
    "    parser.add_argument(\"--filter\", type=int, default=128)\n",
    "    parser.add_argument(\"--max_hops\", type=int, default=6)\n",
    "    parser.add_argument(\"--batch_size\", type=int, default=100)\n",
    "    parser.add_argument(\"--emb\", type=int, default=128)\n",
    "    parser.add_argument(\"--lr\", type=float, default=0.0001)\n",
    "    parser.add_argument(\"--act\", action=\"store_true\")\n",
    "    parser.add_argument(\"--act_loss_weight\", type=float, default=0.001)\n",
    "    parser.add_argument(\"--noam\", action=\"store_true\")\n",
    "    parser.add_argument(\"--verbose\", action=\"store_true\")\n",
    "    return parser.parse_args(args=argtext.split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, criterion, loader):\n",
    "    model.eval()\n",
    "    acc = []\n",
    "    loss = []\n",
    "    for b in loader:\n",
    "        story, query, answer = b.story,b.query,b.answer.squeeze()\n",
    "        if(config.cuda): story, query, answer = story.cuda(), query.cuda(), answer.cuda()\n",
    "        pred_prob = model(story, query)\n",
    "        loss.append(criterion(pred_prob[0], answer).item()) \n",
    "        pred = pred_prob[1].data.max(1)[1] # max func return (max, argmax)\n",
    "        acc.append( pred.eq(answer.data).cpu().numpy() ) \n",
    "\n",
    "    acc = np.concatenate(acc)\n",
    "    acc  = np.mean(acc)\n",
    "    loss = np.mean(loss)\n",
    "    return acc,loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(config):\n",
    "    train_iter, val_iter, test_iter,vocab_len,text_field =get_babidata(config)\n",
    "    model = BabiUTransformer(num_vocab=vocab_len, \n",
    "                    embedding_size=config.emb, \n",
    "                    hidden_size=config.emb, \n",
    "                    num_layers=config.max_hops,\n",
    "                    num_heads=config.heads, \n",
    "                    total_key_depth=config.depth, \n",
    "                    total_value_depth=config.depth,\n",
    "                    filter_size=config.filter,\n",
    "                    act=config.act)\n",
    "    if(config.verbose):\n",
    "        print(model)\n",
    "        print(\"ACT\",config.act)\n",
    "    if(config.cuda): model.cuda()       \n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    if(config.noam):\n",
    "        opt = NoamOpt(config.emb, 1, 4000, torch.optim.Adam(model.parameters(), lr=0, betas=(0.9, 0.98), eps=1e-9))\n",
    "    else:\n",
    "        opt = torch.optim.Adam(model.parameters(),lr=config.lr)\n",
    "    if(config.verbose):\n",
    "        acc_val, loss_val = evaluate(model, criterion, val_iter)\n",
    "        print(\"RAND_VAL ACC:{:.4f}\\t RAND_VAL LOSS:{:.4f}\".format(acc_val, loss_val))\n",
    "    \n",
    "    correct = []\n",
    "    loss_nb = []\n",
    "    cnt_batch = 0\n",
    "    avg_best = 0\n",
    "    cnt = 0\n",
    "    model.train()\n",
    "\n",
    "    for b in train_iter:\n",
    "        story, query, answer = b.story,b.query,b.answer.squeeze()\n",
    "        if(config.cuda): story, query, answer = story.cuda(), query.cuda(), answer.cuda()\n",
    "        if(config.noam):\n",
    "            opt.optimizer.zero_grad()\n",
    "        else:\n",
    "            opt.zero_grad()\n",
    "        pred_prob = model(story, query)\n",
    "        loss = criterion(pred_prob[0], answer)\n",
    "        if(config.act):\n",
    "            R_t = pred_prob[2][0] \n",
    "            N_t = pred_prob[2][1]\n",
    "            p_t = R_t + N_t\n",
    "            avg_p_t = torch.sum(torch.sum(p_t,dim=1)/p_t.size(1))/p_t.size(0)\n",
    "            loss += config.act_loss_weight * avg_p_t.item()\n",
    "\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        ## LOG\n",
    "        loss_nb.append(loss.item())\n",
    "        pred = pred_prob[1].data.max(1)[1] # max func return (max, argmax)\n",
    "        correct.append(np.mean(pred.eq(answer.data).cpu().numpy()))\n",
    "        cnt_batch += 1\n",
    "        if(cnt_batch % 10 == 0):\n",
    "            acc = np.mean(correct)\n",
    "            loss_nb = np.mean(loss_nb)\n",
    "            if(config.verbose):\n",
    "                print(\"TRN ACC:{:.4f}\\tTRN LOSS:{:.4f}\".format(acc, loss_nb))\n",
    "\n",
    "            acc_val, loss_val = evaluate(model, criterion, val_iter)\n",
    "            if(config.verbose):\n",
    "                print(\"VAL ACC:{:.4f}\\tVAL LOSS:{:.4f}\".format(acc_val, loss_val))\n",
    "\n",
    "            if(acc_val > avg_best):\n",
    "            #if(True):\n",
    "                avg_best = acc_val\n",
    "                weights_best = deepcopy(model.state_dict())\n",
    "                cnt = 0\n",
    "            else:\n",
    "                cnt += 1\n",
    "            if(cnt == 45): break\n",
    "            if(avg_best == 1.0): break \n",
    "\n",
    "            correct = []\n",
    "            loss_nb = []\n",
    "            cnt_batch = 0\n",
    "\n",
    "\n",
    "    model.load_state_dict({ name: weights_best[name] for name in weights_best })\n",
    "    acc_test, loss_test = evaluate(model, criterion, test_iter)\n",
    "    if(config.verbose):\n",
    "        print(\"TST ACC:{:.4f}\\tTST LOSS:{:.4f}\".format(acc_val, loss_val))  \n",
    "    return acc_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#__main__\n",
    "config = parse_config(argtext=\"--task 4 --batch_size 32 --cuda --verbose\")\n",
    "for t in range(1,21):\n",
    "    config.task = t\n",
    "    acc = []\n",
    "    for i in range(config.run_avg):\n",
    "        acc.append(main(config))\n",
    "    print(\"Noam\",config.noam,\"ACT\",config.act,\"Task:\",config.task,\"Max:\",max(acc),\"Mean:\",np.mean(acc),\"Std:\",np.std(acc))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
