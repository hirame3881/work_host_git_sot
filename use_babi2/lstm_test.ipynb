{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getopt\n",
    "import sys\n",
    "import os\n",
    "import math\n",
    "import time\n",
    "import argparse\n",
    "import torch\n",
    "import torch as T\n",
    "from torch.autograd import Variable as var\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "\n",
    "#torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description='PyTorch Differentiable Neural Computer')\n",
    "parser.add_argument('-input_size', type=int, default=6, help='dimension of input feature')\n",
    "parser.add_argument('-rnn_type', type=str, default='lstm', help='type of recurrent cells to use for the controller')\n",
    "parser.add_argument('-nhid', type=int, default=64, help='number of hidden units of the inner nn')\n",
    "parser.add_argument('-dropout', type=float, default=0, help='controller dropout')\n",
    "parser.add_argument('-memory_type', type=str, default='dnc', help='dense or sparse memory: dnc | sdnc | sam')\n",
    "\n",
    "parser.add_argument('-nlayer', type=int, default=1, help='number of layers')\n",
    "parser.add_argument('-nhlayer', type=int, default=2, help='number of hidden layers')\n",
    "parser.add_argument('-lr', type=float, default=1e-4, help='initial learning rate')\n",
    "parser.add_argument('-optim', type=str, default='adam', help='learning rule, supports adam|rmsprop')\n",
    "parser.add_argument('-clip', type=float, default=50, help='gradient clipping')\n",
    "\n",
    "parser.add_argument('-batch_size', type=int, default=100, metavar='N', help='batch size')\n",
    "parser.add_argument('-mem_size', type=int, default=20, help='memory dimension')\n",
    "parser.add_argument('-mem_slot', type=int, default=16, help='number of memory slots')\n",
    "parser.add_argument('-read_heads', type=int, default=4, help='number of read heads')\n",
    "parser.add_argument('-sparse_reads', type=int, default=10, help='number of sparse reads per read head')\n",
    "parser.add_argument('-temporal_reads', type=int, default=2, help='number of temporal reads')\n",
    "\n",
    "parser.add_argument('-sequence_max_length', type=int, default=4, metavar='N', help='sequence_max_length')\n",
    "parser.add_argument('-curriculum_increment', type=int, default=0, metavar='N', help='sequence_max_length incrementor per 1K iterations')\n",
    "parser.add_argument('-curriculum_freq', type=int, default=1000, metavar='N', help='sequence_max_length incrementor per 1K iterations')\n",
    "parser.add_argument('-cuda', type=int, default=-1, help='Cuda GPU ID, -1 for CPU')\n",
    "\n",
    "parser.add_argument('-iterations', type=int, default=100000, metavar='N', help='total number of iteration')\n",
    "parser.add_argument('-summarize_freq', type=int, default=100, metavar='N', help='summarize frequency')\n",
    "parser.add_argument('-check_freq', type=int, default=100, metavar='N', help='check point frequency')\n",
    "parser.add_argument('-visdom', action='store_true', help='plot memory content on visdom per -summarize_freq steps')\n",
    "args = parser.parse_args(args=[])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "インプレスの写経を元にしたcopy_lstm_first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:   tensor([[[0.0938, 0.6383, 0.2726, 0.2224, 0.3171, 0.5034, 0.0000],\n",
      "         [0.4009, 0.3630, 0.9441, 0.3897, 0.7335, 0.9221, 0.0000],\n",
      "         [0.4529, 0.9606, 0.9264, 0.3789, 0.6778, 0.7037, 0.0000],\n",
      "         [0.8878, 0.6483, 0.9495, 0.0736, 0.0755, 0.4890, 0.0000],\n",
      "         [0.9427, 0.0769, 0.7107, 0.1870, 0.1975, 0.1911, 0.0000],\n",
      "         [0.3998, 0.1185, 0.5214, 0.4300, 0.7520, 0.2456, 0.0000],\n",
      "         [0.1138, 0.7064, 0.0278, 0.0561, 0.1392, 0.3029, 0.0000],\n",
      "         [0.2495, 0.8236, 0.6098, 0.4970, 0.7401, 0.6144, 0.0000],\n",
      "         [0.0874, 0.6629, 0.9142, 0.2918, 0.9202, 0.1447, 0.0000],\n",
      "         [0.9415, 0.6337, 0.1613, 0.7211, 0.5016, 0.6611, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000]],\n",
      "\n",
      "        [[0.8632, 0.3089, 0.9365, 0.0693, 0.3590, 0.7515, 0.0000],\n",
      "         [0.3358, 0.0983, 0.3881, 0.1498, 0.9716, 0.4647, 0.0000],\n",
      "         [0.7356, 0.1386, 0.2871, 0.9466, 0.5107, 0.1444, 0.0000],\n",
      "         [0.6548, 0.7686, 0.6997, 0.6490, 0.4573, 0.2652, 0.0000],\n",
      "         [0.2634, 0.0575, 0.8569, 0.7121, 0.3854, 0.8825, 0.0000],\n",
      "         [0.3608, 0.3860, 0.3941, 0.1402, 0.1321, 0.4617, 0.0000],\n",
      "         [0.2160, 0.5722, 0.9373, 0.2683, 0.4390, 0.4388, 0.0000],\n",
      "         [0.5381, 0.4868, 0.6030, 0.7391, 0.4294, 0.0703, 0.0000],\n",
      "         [0.5953, 0.4443, 0.4665, 0.0860, 0.5042, 0.6221, 0.0000],\n",
      "         [0.6630, 0.6924, 0.9696, 0.1081, 0.8105, 0.0525, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000]]],\n",
      "       device='cuda:0')\n",
      "target:   tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0938, 0.6383, 0.2726, 0.2224, 0.3171, 0.5034, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.8632, 0.3089, 0.9365, 0.0693, 0.3590, 0.7515, 0.0000]]],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "#Data preparetion\n",
    "def generate_copyfirst(batch_size=2,length=10,size=6,vocab_size=10):\n",
    "    #return (batch, length+1, size+1)\n",
    "    input_story= np.zeros((batch_size, length + 1, size+1), dtype=np.float32)\n",
    "    #input_query=\n",
    "    target_out = np.zeros((batch_size, length + 1, size+1), dtype=np.float32)\n",
    "\n",
    "    sequence = np.random.rand(batch_size, length, size)\n",
    "\n",
    "    input_story[:,:length,:size]=sequence\n",
    "    input_story[:, length, -1] = 1  # QUERY\n",
    "    target_out[:, -1, :size] = sequence[:,0,:]\n",
    "\n",
    "    input_story=torch.from_numpy(input_story).cuda()\n",
    "    target_out=torch.from_numpy(target_out).cuda()\n",
    "    return var(input_story),var(target_out)\n",
    "\n",
    "i,t =generate_copyfirst()\n",
    "print(\"input:  \",i)\n",
    "print(\"target:  \",t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:   tensor([[[0., 1., 1., 0., 1., 0., 0.],\n",
      "         [1., 1., 1., 1., 0., 1., 0.],\n",
      "         [0., 0., 1., 0., 0., 1., 0.],\n",
      "         [1., 1., 0., 1., 1., 1., 0.],\n",
      "         [1., 1., 1., 0., 0., 1., 0.],\n",
      "         [1., 0., 0., 0., 0., 1., 0.],\n",
      "         [1., 1., 0., 0., 1., 1., 0.],\n",
      "         [1., 0., 0., 0., 1., 1., 0.],\n",
      "         [1., 0., 1., 0., 1., 1., 0.],\n",
      "         [0., 0., 0., 1., 1., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 1.]],\n",
      "\n",
      "        [[1., 0., 1., 0., 1., 1., 0.],\n",
      "         [1., 0., 0., 1., 1., 0., 0.],\n",
      "         [1., 1., 1., 0., 0., 1., 0.],\n",
      "         [1., 0., 0., 1., 1., 0., 0.],\n",
      "         [0., 1., 0., 0., 1., 1., 0.],\n",
      "         [1., 1., 1., 1., 0., 1., 0.],\n",
      "         [0., 0., 0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 0., 1., 1., 0.],\n",
      "         [1., 1., 0., 1., 0., 0., 0.],\n",
      "         [1., 0., 1., 1., 0., 1., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 1.]]], device='cuda:0')\n",
      "target:   tensor([[[0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 1., 1., 0., 1., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0.],\n",
      "         [1., 0., 1., 0., 1., 1., 0.]]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "def discrete_copyfirst(batch_size=2,length=10,size=6,vocab_size=10):\n",
    "    #return (batch, length+1, size+1)\n",
    "    input_story= np.zeros((batch_size, length + 1, size+1), dtype=np.float32)\n",
    "    #input_query=\n",
    "    target_out = np.zeros((batch_size, length + 1, size+1), dtype=np.float32)\n",
    "\n",
    "    sequence = np.random.binomial(1,0.5,(batch_size, length, size))\n",
    "\n",
    "    input_story[:,:length,:size]=sequence\n",
    "    input_story[:, length, -1] = 1  # QUERY\n",
    "    target_out[:, -1, :size] = sequence[:,0,:]\n",
    "\n",
    "    input_story=torch.from_numpy(input_story).cuda()\n",
    "    target_out=torch.from_numpy(target_out).cuda()\n",
    "    return var(input_story),var(target_out)\n",
    "\n",
    "i,t =discrete_copyfirst()\n",
    "print(\"input:  \",i)\n",
    "print(\"target:  \",t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLSTMCopyFirst(nn.Module):\n",
    "    # モデルで使う各ネットワークをコンストラクタで定義\n",
    "    def __init__(self, input_dim, hidden_dim, tagset_size):\n",
    "        # 親クラスのコンストラクタ。決まり文句\n",
    "        super(MyLSTMCopyFirst, self).__init__()\n",
    "        # 隠れ層の次元数。これは好きな値に設定しても行列計算の過程で出力には出てこないので。\n",
    "        self.hidden_dim = hidden_dim\n",
    "        # LSTMの隠れ層。これ１つでOK。超便利。\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim)\n",
    "        # LSTMの出力を受け取って全結合してsoftmaxに食わせるための１層のネットワーク\n",
    "        self.hidden2tag = nn.Linear(hidden_dim, tagset_size)\n",
    "        self.flag=True\n",
    "    # 順伝播処理はforward関数に記載\n",
    "    def forward(self, sentence,hidden=None):\n",
    "        # 2次元テンソルをLSTMに食わせられる様にviewで３次元テンソルにした上でLSTMへ流す。\n",
    "        # 上記で説明した様にmany to oneのタスクを解きたいので、第二戻り値＝hiddenだけ使う。　babiもmany to oneのはず\n",
    "\n",
    "        if (hidden==None):\n",
    "            _, lstm_out = self.lstm(sentence.view(1,len(sentence),  -1)) #(1,batch, size)\n",
    "        else:\n",
    "            _,lstm_out = self.lstm(sentence.view(1,len(sentence),  -1),hidden)\n",
    "        \n",
    "        #sentence = sentence.permute(1,0,2)\n",
    "        # lstm_out[0]は３次元テンソルになってしまっているので2次元に調整して全結合。\n",
    "        #if self.flag:\n",
    "        #    print(\"lstm_out[0] reshape\")\n",
    "        #    print(lstm_out[0].view(-1, self.hidden_dim))\n",
    "        tag_space = self.hidden2tag(lstm_out[0].view(-1, self.hidden_dim))\n",
    "        if self.flag:\n",
    "            print(\"linear out\")\n",
    "            print(tag_space)\n",
    "            self.flag=False\n",
    "        #tag_space=tag_space.view(len(sentence),1,-1)\n",
    "        return tag_space,lstm_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_criterion(predictions, targets):\n",
    "  return T.mean(\n",
    "      -1 * F.logsigmoid(predictions) * (targets) - T.log(1 - F.sigmoid(predictions) + 1e-9) * (1 - targets)\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.0715, -0.0785,  0.0323, -0.0032,  0.0967, -0.1989,  0.0276,\n",
      "          -0.0375,  0.0949,  0.0933,  0.0562, -0.0011,  0.0219,  0.0183,\n",
      "           0.0941, -0.0504],\n",
      "         [-0.0273, -0.0067,  0.0576, -0.0294,  0.0972, -0.2272,  0.0247,\n",
      "          -0.0352,  0.1432,  0.1039,  0.0438, -0.0338, -0.0094,  0.0822,\n",
      "           0.0149, -0.0296]]], device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
      "tensor([[[-0.1850,  0.2205, -0.0138,  0.0902,  0.1512, -0.0903, -0.1336],\n",
      "         [-0.2128,  0.2361, -0.0318,  0.0566,  0.1380, -0.0578, -0.0900]]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "epoch: 0  loss: 0.2993655204772949\n",
      "epoch: 20  loss: 0.23127497173845768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/loss.py:446: UserWarning: Using a target size (torch.Size([2, 7])) that is different to the input size (torch.Size([2, 1, 7])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 40  loss: 0.1777334939688444\n",
      "epoch: 60  loss: 0.12730709407478571\n",
      "epoch: 80  loss: 0.11438267435878516\n",
      "epoch: 100  loss: 0.09148032125085592\n",
      "epoch: 120  loss: 0.08888919055461883\n",
      "epoch: 140  loss: 0.08276105672121048\n",
      "epoch: 160  loss: 0.0834938095882535\n",
      "epoch: 180  loss: 0.07841408289968968\n",
      "epoch: 200  loss: 0.0717847978696227\n",
      "epoch: 220  loss: 0.06774993389844894\n",
      "epoch: 240  loss: 0.07710188757628203\n",
      "epoch: 260  loss: 0.07159148193895817\n",
      "epoch: 280  loss: 0.08199394382536411\n",
      "epoch: 300  loss: 0.0832165228202939\n"
     ]
    }
   ],
   "source": [
    "# model generate, optimizer and criterion setting\n",
    "batch_size=2\n",
    "length=10\n",
    "size=6\n",
    "vocab_size=10\n",
    "\n",
    "model= MyLSTMCopyFirst(input_dim=size+1, hidden_dim=16, tagset_size=size+1).cuda()\n",
    "optimizer = optim.SGD(model.parameters(),lr=0.03)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "\n",
    "#Learn\n",
    "n = 2    ##  データのサイズ\n",
    "bs = 2   ##  バッチのサイズ\n",
    "iterations=300\n",
    "summarize_freq=20\n",
    "last_save_losses = []\n",
    "\n",
    "model.train()\n",
    "for epoch in range(iterations + 1):\n",
    "    #print(\"\\rIteration {ep}/{tot}\".format(ep=epoch, tot=iterations))\n",
    "    input_story, target_out = generate_copyfirst()\n",
    "\n",
    "\n",
    "    for time in range(length+1): #DataLoader　ではないと思う。layer forwardにあたる\n",
    "        sentence =input_story[:,time,:]\n",
    "        target=target_out[:,time,:]\n",
    "        output = model(sentence)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        #最後のステップだけloss計算する\n",
    "        if (time==length):\n",
    "            loss = criterion(output,target)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            loss_value = loss.item()\n",
    "            last_save_losses.append(loss_value)\n",
    "\n",
    "    summarize = (epoch % summarize_freq == 0)\n",
    "    if summarize:\n",
    "        loss = np.mean(last_save_losses)\n",
    "        print(\"epoch:\",epoch,\" loss:\",loss)\n",
    "        last_save_losses = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tloss: 1.7892667055130005\n"
     ]
    }
   ],
   "source": [
    "#Test\n",
    "test_story, test_y = generate_copyfirst()\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for time in range(length+1): #DataLoader　ではないと思う。layer forwardにあたる\n",
    "        tsentence =test_story[:,time,:]\n",
    "        ttarget=test_y[:,time,:]\n",
    "        toutput = model(tsentence)\n",
    "\n",
    "        #最後のステップだけloss計算する\n",
    "        if (time==length):\n",
    "            tloss = criterion(toutput,ttarget)\n",
    "            tloss_value = tloss.item()\n",
    "            print(\"tloss:\",tloss_value)\n",
    "\n",
    "#連続地のコピーにしたけど本来↓\n",
    "    #output1= model(xtest)\n",
    "    #ans = torch.argmax(output1,1)\n",
    "    #print(((ytest == ans).sum().float() / len(ans) ).item() )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    離散値"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear out\n",
      "tensor([[ 0.1772,  0.0809,  0.1295,  0.0918,  0.0759, -0.2118, -0.0059],\n",
      "        [ 0.2065,  0.1008,  0.1121,  0.0846,  0.0574, -0.2166,  0.0189]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "epoch: 0  loss: 0.2822442650794983\n",
      "epoch: 100  loss: 0.2409405355155468\n",
      "epoch: 200  loss: 0.2161868679523468\n",
      "epoch: 300  loss: 0.2165006157755852\n",
      "epoch: 400  loss: 0.21738955289125442\n",
      "epoch: 500  loss: 0.21823563307523727\n",
      "epoch: 600  loss: 0.2162562595307827\n",
      "epoch: 700  loss: 0.21665824010968207\n",
      "epoch: 800  loss: 0.216469007730484\n",
      "epoch: 900  loss: 0.21530019193887712\n",
      "epoch: 1000  loss: 0.2175290195643902\n",
      "epoch: 1100  loss: 0.21650463759899138\n",
      "epoch: 1200  loss: 0.21649720922112464\n",
      "epoch: 1300  loss: 0.21754909217357635\n",
      "epoch: 1400  loss: 0.21618148297071457\n",
      "epoch: 1500  loss: 0.21707578703761102\n"
     ]
    }
   ],
   "source": [
    "# model generate, optimizer and criterion setting\n",
    "batch_size=2\n",
    "length=10\n",
    "size=6\n",
    "vocab_size=10\n",
    "\n",
    "model= MyLSTMCopyFirst(input_dim=size+1, hidden_dim=16, tagset_size=size+1).cuda()\n",
    "optimizer = optim.SGD(model.parameters(),lr=0.1)\n",
    "\n",
    "#Learn\n",
    "n = 2    ##  データのサイズ\n",
    "bs = 2   ##  バッチのサイズ\n",
    "iterations=1500\n",
    "summarize_freq=iterations/15\n",
    "last_save_losses = []\n",
    "\n",
    "model.train()\n",
    "for epoch in range(iterations + 1):\n",
    "    #print(\"\\rIteration {ep}/{tot}\".format(ep=epoch, tot=iterations))\n",
    "    input_story, target_out = discrete_copyfirst()\n",
    "\n",
    "    hidden=None\n",
    "    for time in range(length+1): #DataLoader　ではないと思う。layer forwardにあたる\n",
    "        sentence =input_story[:,time,:]\n",
    "        target=target_out[:,time,:]\n",
    "\n",
    "        if time==0:\n",
    "            output,hidden = model(sentence)\n",
    "        else:\n",
    "            output,hidden = model(sentence,hidden)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        #最後のステップだけloss計算する\n",
    "        if (time==length):\n",
    "            loss = criterion((output),target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            loss_value = loss.item()\n",
    "            last_save_losses.append(loss_value)\n",
    "    hidden=None\n",
    "    summarize = (epoch % summarize_freq == 0)\n",
    "    if summarize:\n",
    "        loss = np.mean(last_save_losses)\n",
    "        print(\"epoch:\",epoch,\" loss:\",loss)\n",
    "        last_save_losses = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 0., 1., 1., 1., 0.],\n",
      "        [1., 0., 0., 0., 1., 0., 0.]], device='cuda:0')\n",
      "tensor([[0.4641, 0.5617, 0.4601, 0.5492, 0.4401, 0.5182, 0.0095],\n",
      "        [0.4501, 0.5652, 0.4723, 0.5291, 0.4427, 0.5337, 0.0047]],\n",
      "       device='cuda:0')\n",
      "tloss: 0.6893427968025208\n",
      "predict: [[0.46409285 0.561737   0.46010253 0.5492228  0.44012043 0.51824784\n",
      "  0.00952974]\n",
      " [0.45011994 0.5651748  0.47226402 0.529108   0.44270962 0.53370535\n",
      "  0.00471528]]\n",
      "real: [[1. 1. 0. 1. 1. 1. 0.]\n",
      " [1. 0. 0. 0. 1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "#Test\n",
    "test_story, test_y = discrete_copyfirst()\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    hidden=None\n",
    "    for time in range(length+1): #DataLoader　ではないと思う。layer forwardにあたる\n",
    "        tsentence =test_story[:,time,:]\n",
    "        ttarget=test_y[:,time,:]\n",
    "        if time==0:\n",
    "            toutput,hidden = model(tsentence)\n",
    "        else:\n",
    "            toutput,hidden = model(tsentence,hidden)\n",
    "\n",
    "        #最後のステップだけloss計算する\n",
    "        if (time==length):\n",
    "            print(ttarget)\n",
    "            print(toutput)\n",
    "            tloss = my_criterion(toutput,ttarget)\n",
    "            tloss_value = tloss.item()\n",
    "            print(\"tloss:\",tloss_value)\n",
    "\n",
    "            toutput = toutput.cpu().numpy()\n",
    "            ttarget = ttarget.cpu().numpy()\n",
    "            print(\"predict:\",toutput)\n",
    "            print(\"real:\",ttarget)\n",
    "#連続地のコピーにしたけど本来↓\n",
    "    #output1= model(xtest)\n",
    "    #ans = torch.argmax(output1,1)\n",
    "    #print(((ytest == ans).sum().float() / len(ans) ).item() )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hiddenとoutputのサイズが共通な以上、全結合層を挟まないとhidden_sizeが分類クラス数あるいはvocab_sizeに固定されてしまうよ　　\n",
    "扱うのがコピーから文章になると、embedding層やvocab_size引数が必要になるよ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLSTMClassifier(nn.Module):\n",
    "    # モデルで使う各ネットワークをコンストラクタで定義\n",
    "    def __init__(self, embedding_dim, hidden_dim, vocab_size, tagset_size):\n",
    "        # 親クラスのコンストラクタ。決まり文句\n",
    "        super(MyLSTMClassifier, self).__init__()\n",
    "        # 隠れ層の次元数。これは好きな値に設定しても行列計算の過程で出力には出てこないので。\n",
    "        self.hidden_dim = hidden_dim\n",
    "        # LSTMの隠れ層。これ１つでOK。超便利。\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim)\n",
    "        # LSTMの出力を受け取って全結合してsoftmaxに食わせるための１層のネットワーク\n",
    "        self.hidden2tag = nn.Linear(hidden_dim, tagset_size)\n",
    "        # softmaxのLog版。dim=0で列、dim=1で行方向を確率変換。\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    # 順伝播処理はforward関数に記載\n",
    "    def forward(self, sentence):\n",
    "        # 2次元テンソルをLSTMに食わせられる様にviewで３次元テンソルにした上でLSTMへ流す。\n",
    "        # 上記で説明した様にmany to oneのタスクを解きたいので、第二戻り値＝hiddenだけ使う。　babiもmany to oneのはず\n",
    "        _, lstm_out = self.lstm(sentence.view(len(sentence), 1, -1))\n",
    "        # lstm_out[0]は３次元テンソルになってしまっているので2次元に調整して全結合。\n",
    "        tag_space = self.hidden2tag(lstm_out[0].view(-1, self.hidden_dim))\n",
    "        # softmaxに食わせて、確率として表現\n",
    "        tag_scores = self.softmax(tag_space)\n",
    "        return tag_scores\n",
    "        #hiddenは明示的にforwardの入力にしなくても大丈夫"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 4 required positional arguments: 'embedding_dim', 'hidden_dim', 'vocab_size', and 'tagset_size'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [9], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# model generate, optimizer and criterion setting\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m model\u001b[38;5;241m=\u001b[39m \u001b[43mMyLSTMClassifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[1;32m      4\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mSGD(model\u001b[38;5;241m.\u001b[39mparameters(),lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m)\n\u001b[1;32m      5\u001b[0m criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() missing 4 required positional arguments: 'embedding_dim', 'hidden_dim', 'vocab_size', and 'tagset_size'"
     ]
    }
   ],
   "source": [
    "# model generate, optimizer and criterion setting\n",
    "\n",
    "model= MyLSTMClassifier().cuda()\n",
    "optimizer = optim.SGD(model.parameters(),lr=0.1)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Learn\n",
    "\n",
    "n =     ##  データのサイズ\n",
    "bs =    ##  バッチのサイズ\n",
    "itr=5\n",
    "\n",
    "model.train()\n",
    "for i in range(itr):\n",
    "    idx = np.random.permutation(n)\n",
    "    for j in range(0,n,bs):\n",
    "        xtm = xtrain[idx[j:(j+bs) if (j+bs)<n else n]]\n",
    "        ytm = ytrain[idx[j:(j+bs) if (j+bs) < n else n]]\n",
    "        output = model(xtm)\n",
    "        loss = criterion(output,ytm)\n",
    "        print(i,j,loss.item())\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    output1= model(xtest)\n",
    "    ans = torch.argmax(output1,1)\n",
    "    print(((ytest == ans).sum().float() / len(ans) ).item() )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "↓は文章をあつかうやつ　コピーの次に"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model\n",
    "\n",
    "class MyLSTMClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyLSTM,self).__init__()\n",
    "        self.l1=nn.Linear(4,6)\n",
    "        self.l2=nn.Linear(6,3)\n",
    "    def forward(self,x):\n",
    "        h1=torch.sigmoid(self.l1(x))\n",
    "        h2=self.l2(h1)\n",
    "        return h2\n",
    "\n",
    "class MyLSTMClassifier(nn.Module):\n",
    "    # モデルで使う各ネットワークをコンストラクタで定義\n",
    "    def __init__(self, embedding_dim, hidden_dim, vocab_size, tagset_size):\n",
    "        # 親クラスのコンストラクタ。決まり文句\n",
    "        super(MyLSTMClassifier, self).__init__()\n",
    "        # 隠れ層の次元数。これは好きな値に設定しても行列計算の過程で出力には出てこないので。\n",
    "        self.hidden_dim = hidden_dim\n",
    "        # インプットの単語をベクトル化するために使う\n",
    "        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        # LSTMの隠れ層。これ１つでOK。超便利。\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim)\n",
    "        # LSTMの出力を受け取って全結合してsoftmaxに食わせるための１層のネットワーク\n",
    "        self.hidden2tag = nn.Linear(hidden_dim, tagset_size)\n",
    "        # softmaxのLog版。dim=0で列、dim=1で行方向を確率変換。\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    # 順伝播処理はforward関数に記載\n",
    "    def forward(self, sentence):\n",
    "        # 文章内の各単語をベクトル化して出力。2次元のテンソル\n",
    "        embeds = self.word_embeddings(sentence)\n",
    "        # 2次元テンソルをLSTMに食わせられる様にviewで３次元テンソルにした上でLSTMへ流す。\n",
    "        # 上記で説明した様にmany to oneのタスクを解きたいので、第二戻り値だけ使う。\n",
    "        _, lstm_out = self.lstm(embeds.view(len(sentence), 1, -1))\n",
    "        # lstm_out[0]は３次元テンソルになってしまっているので2次元に調整して全結合。\n",
    "        tag_space = self.hidden2tag(lstm_out[0].view(-1, self.hidden_dim))\n",
    "        # softmaxに食わせて、確率として表現\n",
    "        tag_scores = self.softmax(tag_space)\n",
    "        return tag_scores"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
