{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "どう考えてもPandasを入れたほうがいい  \n",
    "まあ作ったものは仕方ないので、読み出したあとdicをまとめる操作以降をPandasする"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数値をtxtファイルに保存する関数を作る　trainer mainで呼ぶ  \n",
    "１行目のdescription(default=#),2行目以降の　「属性：値」　は引数として自由に取る    \n",
    "保存先ディレクトリとファイル接頭辞もとりあえず引数に取ることにして、訓練のmain.pyが参照する config.jsonにそのパスは入れておく形式で行く  \n",
    "  \n",
    "ファイルidをどうすればいいかわからないが、fileidを引数にとってそのファイルに書き込む形式にするとjoinも非joinも対応できるか  \n",
    "やっぱ最初にid一覧を引き取って、そのぶんだけdescriptionを書く初期化を行うことにする  \n",
    "非joinの場合のみ、1Storing()=1ファイル となる "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "freeidについてはrunidは考慮しなくていい。freeid or babitaskidのことを指す    \n",
    "-/ntm_vlgiitr/associative/rrnn/自由_runid1.txt  \n",
    "-babi/rrnn/id1/task1.txt  \n",
    "読み込む.jsonごとに、-/ntm_vlgiitr/associative までは書いておける  \n",
    "モデルごとに分ける次の階層については、.pyに書きたいところだが繰り返し書くのも良くない  \n",
    " →utilとしてここに書くことにした。必要な引数を渡すとディレクトリ名を返す。比較対象モデルのデータはここに持つ感じで  \n",
    "runidはtrain.pyの引数からscorestoringの引数へ\n",
    "自由は今までfilename_idだったとこ　将来的に改善しそうな部分を書く。改善後は別モデルdirに分けられるけど  \n",
    "commonは廃止。commonで表現すべきところはdir分けをする  \n",
    "batch_size などはdescriptionに辞書形式で入れる  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import datetime\n",
    "import json\n",
    "class ScoreStoring(): #1ディレクトリ。引数はconfig only これはjointのときだけ使うことにする\n",
    "    #data_config[\"savescore_dir\"],data_config[\"filename_common\"]\n",
    "    def __init__(self, data_config,fileid_str_list,dir_modelname,runid,file_description,babi=False,dir_descrption=None):\n",
    "        file_description[\"datetime\"]=str(datetime.datetime.now(datetime.timezone(datetime.timedelta(hours=9))))\n",
    "        print(\"filename_ids:\",fileid_str_list,\"runid:\",runid)\n",
    "        #fileid_str_list : [\"1\",\"2\",\"3\"... ] など 日付にするのも良い〜\n",
    "        self.filepath_dic ={}\n",
    "        if (not babi) and len(fileid_str_list)!=1:raise ValueError(\"fileid list size must be 1 ohter than babi\")\n",
    "        if babi:raise ValueError(\"not implemented\")\n",
    "        for freeid in fileid_str_list:\n",
    "            self.filepath_dic[freeid] =os.path.join(data_config[\"savescore_dir\"],dir_modelname,freeid+\"_runid\"+str(runid)+\".txt\")\n",
    "            print(\"score_path:\",self.filepath_dic[freeid] )\n",
    "            #fileがすでにあるならその中身を初期化し、１行目にdescriptionを書く\n",
    "            with open( self.filepath_dic[freeid], \"w\" , encoding= \"utf-8\" ) as f:\n",
    "                #f.write(file_description+rowAttr+\":\"+rowVal+\"\\n\")\n",
    "                f.write(json.dumps(file_description)+\"\\n\")\n",
    "        \n",
    "    def store(self,fileid_str,attr,val):\n",
    "        filepath=self.filepath_dic[fileid_str]\n",
    "        with open( filepath, \"a\" , encoding= \"utf-8\" ) as f:\n",
    "            f.write(str(attr)+\":\"+str(val)+\"\\n\")\n",
    "\n",
    "        ##writelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#xとyが１；１以外でも、ｙが複数合っても対応できるようにしたい"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ScoreStoringLoader(): \n",
    "    #data_config[\"savescore_dir\"],data_config[\"filename_common\"]\n",
    "    def __init__(self,savescore_dir,modeldir_list,fileid,runid_list,desc_lines=1,sep=\":\"):\n",
    "        self.desc_lines =desc_lines\n",
    "        self.sep=sep\n",
    "        print(\"run_ids:\",runid_list)\n",
    "        self.runid_list_str =[\"runid\"+str(rid) for rid in runid_list]\n",
    "        if type(fileid)!=type(\" \"):raise ValueError(\"fileid must be str. 1 Loader makes 1 image\")\n",
    "        self.data_dic={} #{\"rrnn\":\n",
    "                            #{\"batch_size\":1600,\n",
    "                            # \"runid1\":{\"epoch\":[0,10,20...]  , \"accuracy\":[0.7,0.8,0.9 ...]  , \"z\"...}  \n",
    "                            #}, \"sortrrnn\":...}\n",
    "\n",
    "        for modeldir in modeldir_list:\n",
    "            self.data_dic[modeldir] ={}\n",
    "            for idx,rid in enumerate( self.runid_list_str):\n",
    "                data_path=os.path.join(savescore_dir,modeldir,fileid+\"_\"+rid+\".txt\")\n",
    "                with open(data_path, \"r\" , encoding= \"utf-8\" ) as f:\n",
    "                    filecontent=f.read().splitlines()\n",
    "                    file_description=json.loads(filecontent[0])\n",
    "                    lines=filecontent[desc_lines:]\n",
    "\n",
    "                    if idx==0:self.data_dic[modeldir][\"batch_size\"]=int(file_description[\"batch_size\"])\n",
    "                    if self.data_dic[modeldir][\"batch_size\"]!=int(file_description[\"batch_size\"]):raise ValueError(\"inconsistent batch_size over runid\")\n",
    "\n",
    "                    listed_data = [line.split(self.sep) for line in lines]\n",
    "                    listed_data = np.array([[float(data) for data in line] for line in listed_data])\n",
    "                    self.data_dic[modeldir][rid] ={file_description[\"rowAttr\"]:listed_data[:,0],file_description[\"rowVal\"]:listed_data[:,1]}\n",
    "\n",
    "    def get_data_dic(self): \n",
    "        return self.data_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3131940118.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn [4], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    data_config=\u001b[0m\n\u001b[0m                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def get_dirname(infer_type,sort_flag):\n",
    "    dir_modelname=[\"ntm\",\"rrnn\",\"sortrrnn\"]\n",
    "    if infer_type==1:\n",
    "        if sort_flag:\n",
    "            return dir_modelname[2]\n",
    "        else:\n",
    "            return dir_modelname[1]\n",
    "    else:\n",
    "        return dir_modelname[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
